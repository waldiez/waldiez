{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc44f88",
   "metadata": {},
   "source": [
    "# Name: On-boarding Async\n",
    "\n",
    "## Description: Async version of Sequential Chats and Customer Onboarding\n",
    "\n",
    "## Tags: Sequential, Customer, On-boarding, Onboarding\n",
    "\n",
    "###ðŸ§© generated with â¤ï¸ by Waldiez.\n",
    "\n",
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1341000",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# # !{sys.executable} -m pip install -q ag2[anthropic]==0.10.1 ag2[openai]==0.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f982971",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903e505",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import csv\n",
    "import importlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "import sys\n",
    "import threading\n",
    "import traceback\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from types import ModuleType\n",
    "from typing import (\n",
    "    Annotated,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Coroutine,\n",
    "    Dict,\n",
    "    List,\n",
    "    Optional,\n",
    "    Set,\n",
    "    Tuple,\n",
    "    TypedDict,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "import aiofiles\n",
    "import aiosqlite\n",
    "import anyio\n",
    "import nest_asyncio\n",
    "from aiocsv import AsyncDictWriter\n",
    "\n",
    "import autogen  # type: ignore\n",
    "from autogen import (\n",
    "    Agent,\n",
    "    AssistantAgent,\n",
    "    Cache,\n",
    "    ChatResult,\n",
    "    ConversableAgent,\n",
    "    GroupChat,\n",
    "    UserProxyAgent,\n",
    "    runtime_logging,\n",
    ")\n",
    "from autogen.agentchat.group import ContextVariables\n",
    "from autogen.agentchat.group.patterns.pattern import Pattern\n",
    "from autogen.events import BaseEvent\n",
    "from autogen.io.run_response import (\n",
    "    AsyncRunResponseProtocol,\n",
    "    RunResponseProtocol,\n",
    ")\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# pylint: disable=broad-exception-caught\n",
    "try:\n",
    "    nest_asyncio.apply()\n",
    "except BaseException:\n",
    "    pass  # maybe on uvloop?\n",
    "# Common environment variable setup for Waldiez flows\n",
    "load_dotenv(override=True)\n",
    "os.environ[\"AUTOGEN_USE_DOCKER\"] = \"0\"\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"False\"\n",
    "#\n",
    "# let's try to avoid:\n",
    "# module 'numpy' has no attribute '_no_nep50_warning'\"\n",
    "# ref: https://github.com/numpy/numpy/blob/v2.2.2/doc/source/release/2.2.0-notes.rst#nep-50-promotion-state-option-removed\n",
    "os.environ[\"NEP50_DEPRECATION_WARNING\"] = \"0\"\n",
    "os.environ[\"NEP50_DISABLE_WARNING\"] = \"1\"\n",
    "os.environ[\"NPY_PROMOTION_STATE\"] = \"weak\"\n",
    "if not hasattr(np, \"_no_pep50_warning\"):\n",
    "\n",
    "    import contextlib\n",
    "    from typing import Generator\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _np_no_nep50_warning() -> Generator[None, None, None]:\n",
    "        \"\"\"Dummy function to avoid the warning.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        None\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "        yield\n",
    "\n",
    "    setattr(np, \"_no_pep50_warning\", _np_no_nep50_warning)  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e2fc3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_logging() -> None:\n",
    "    \"\"\"Start logging.\"\"\"\n",
    "    # pylint: disable=import-outside-toplevel\n",
    "    from anyio.from_thread import start_blocking_portal\n",
    "\n",
    "    with start_blocking_portal(backend=\"asyncio\") as portal:\n",
    "        portal.call(\n",
    "            runtime_logging.start,\n",
    "            None,\n",
    "            \"sqlite\",\n",
    "            {\"dbname\": \"flow.db\"},\n",
    "        )\n",
    "\n",
    "\n",
    "start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1bdab8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Load model API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f7bce",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# This section assumes that a file named:\n",
    "# \"On_boarding_Async_api_keys.py\"\n",
    "# exists in the same directory as this file.\n",
    "# This file contains the API keys for the models used in this flow.\n",
    "# It should be .gitignored and not shared publicly.\n",
    "# If this file is not present, you can either create it manually\n",
    "# or change the way API keys are loaded in the flow.\n",
    "\n",
    "\n",
    "def load_api_key_module(flow_name: str) -> ModuleType:\n",
    "    \"\"\"Load the api key module.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flow_name : str\n",
    "        The flow name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ModuleType\n",
    "        The api keys loading module.\n",
    "    \"\"\"\n",
    "    module_name = f\"{flow_name}_api_keys\"\n",
    "    if module_name in sys.modules:\n",
    "        return importlib.reload(sys.modules[module_name])\n",
    "    return importlib.import_module(module_name)\n",
    "\n",
    "\n",
    "__MODELS_MODULE__ = load_api_key_module(\"On_boarding_Async\")\n",
    "\n",
    "\n",
    "def get_On_boarding_Async_model_api_key(model_name: str) -> str:\n",
    "    \"\"\"Get the model api key.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        The model name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The model api key.\n",
    "    \"\"\"\n",
    "    return __MODELS_MODULE__.get_On_boarding_Async_model_api_key(model_name)\n",
    "\n",
    "\n",
    "class GroupDict(TypedDict):\n",
    "    \"\"\"Group related global dict.\"\"\"\n",
    "\n",
    "    chats: dict[str, GroupChat]\n",
    "    patterns: dict[str, Pattern]\n",
    "\n",
    "\n",
    "__GROUP__: GroupDict = {\"chats\": {}, \"patterns\": {}}\n",
    "\n",
    "__AGENTS__: dict[str, ConversableAgent] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23932e24",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_3_7_sonnet_20250219_llm_config: dict[str, Any] = {\n",
    "    \"model\": \"claude-3-7-sonnet-20250219\",\n",
    "    \"api_type\": \"anthropic\",\n",
    "    \"api_key\": get_On_boarding_Async_model_api_key(\n",
    "        \"claude_3_7_sonnet_20250219\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "gpt_3_5_turbo_llm_config: dict[str, Any] = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"api_type\": \"openai\",\n",
    "    \"api_key\": get_On_boarding_Async_model_api_key(\"gpt_3_5_turbo\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4191ece",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3fea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_engagement_agent = AssistantAgent(\n",
    "    name=\"customer_engagement_agent\",\n",
    "    description=\"A customer_engagement_agent agent.\",\n",
    "    system_message=\"You are a helpful customer service agent here to provide fun for the customer based on the user's personal information and topic preferences. This could include fun facts, jokes, or interesting stories. Make sure to make it engaging and fun! Return 'TERMINATE' when you are done.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda x: any(\n",
    "        isinstance(x, dict)\n",
    "        and x.get(\"content\", \"\")\n",
    "        and isinstance(x.get(\"content\", \"\"), str)\n",
    "        and x.get(\"content\", \"\") == keyword\n",
    "        for keyword in [\"TERMINATE\"]\n",
    "    ),\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_3_5_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"customer_engagement_agent\"] = customer_engagement_agent\n",
    "\n",
    "customer_proxy = UserProxyAgent(\n",
    "    name=\"customer_proxy\",\n",
    "    description=\"A new User proxy agent\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    llm_config=False,\n",
    ")\n",
    "\n",
    "__AGENTS__[\"customer_proxy\"] = customer_proxy\n",
    "\n",
    "personal_information_agent = AssistantAgent(\n",
    "    name=\"personal_information_agent\",\n",
    "    description=\"A customer on-boarding agent.\",\n",
    "    system_message=\"You are a helpful customer on-boarding agent, you are here to help new customers get started with our product. Your job is to gather customer's name and location. Do not ask for other information. Return 'TERMINATE' when you have gathered all the information.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda x: any(\n",
    "        isinstance(x, dict)\n",
    "        and x.get(\"content\", \"\")\n",
    "        and isinstance(x.get(\"content\", \"\"), str)\n",
    "        and x.get(\"content\", \"\") == keyword\n",
    "        for keyword in [\"TERMINATE\"]\n",
    "    ),\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            claude_3_7_sonnet_20250219_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"personal_information_agent\"] = personal_information_agent\n",
    "\n",
    "topic_preference_agent = AssistantAgent(\n",
    "    name=\"topic_preference_agent\",\n",
    "    description=\"A topic preference agent\",\n",
    "    system_message=\"You are a helpful customer service agent here to provide fun for the customer based on the user's personal information and topic preferences. This could include fun facts, jokes, or interesting stories. Make sure to make it engaging and fun! Return 'TERMINATE' when you are done.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda x: any(\n",
    "        isinstance(x, dict)\n",
    "        and x.get(\"content\", \"\")\n",
    "        and isinstance(x.get(\"content\", \"\"), str)\n",
    "        and x.get(\"content\", \"\") == keyword\n",
    "        for keyword in [\"TERMINATE\"]\n",
    "    ),\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            claude_3_7_sonnet_20250219_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"topic_preference_agent\"] = topic_preference_agent\n",
    "\n",
    "__INITIAL_MSG__ = [\n",
    "    {\n",
    "        \"recipient\": customer_proxy,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\": \"Return the customer information into as JSON object only: {'name': '', 'location': ''}\",\n",
    "            \"summary_role\": \"user\",\n",
    "        },\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\": True,\n",
    "        \"chat_id\": 0,\n",
    "        \"message\": \"Hello, I'm here to help you get started with our product. Could you tell me your name and location?\",\n",
    "    },\n",
    "    {\n",
    "        \"sender\": topic_preference_agent,\n",
    "        \"recipient\": customer_proxy,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\": \"Return the customer information into as JSON object only: {'topic_of_interest': ''}\",\n",
    "            \"summary_role\": \"user\",\n",
    "        },\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\": True,\n",
    "        \"chat_id\": 1,\n",
    "        \"prerequisites\": [0],\n",
    "        \"message\": \"Great! Could you tell me what topics you are interested in reading about?\",\n",
    "    },\n",
    "    {\n",
    "        \"sender\": customer_proxy,\n",
    "        \"recipient\": customer_engagement_agent,\n",
    "        \"summary_method\": \"last_msg\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\": True,\n",
    "        \"chat_id\": 2,\n",
    "        \"prerequisites\": [1],\n",
    "        \"message\": \"Let's find something fun to read.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "async def get_sqlite_out(dbname: str, table: str, csv_file: str) -> None:\n",
    "    \"\"\"Convert a sqlite table to csv and json files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dbname : str\n",
    "        The sqlite database name.\n",
    "    table : str\n",
    "        The table name.\n",
    "    csv_file : str\n",
    "        The csv file name.\n",
    "    \"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements\n",
    "    try:\n",
    "        conn = await aiosqlite.connect(dbname)\n",
    "    except BaseException:\n",
    "        return\n",
    "    query = f\"SELECT * FROM {table}\"  # nosec\n",
    "    try:\n",
    "        cursor = await conn.execute(query)\n",
    "    except BaseException:\n",
    "        await conn.close()\n",
    "        return\n",
    "    try:\n",
    "        rows = await cursor.fetchall()\n",
    "        column_names = [description[0] for description in cursor.description]\n",
    "        data = [dict(zip(column_names, row, strict=True)) for row in rows]\n",
    "        await cursor.close()\n",
    "        await conn.close()\n",
    "    except BaseException:\n",
    "        try:\n",
    "            await cursor.close()\n",
    "            await conn.close()\n",
    "        except BaseException:\n",
    "            pass\n",
    "        return\n",
    "    try:\n",
    "        async with aiofiles.open(\n",
    "            csv_file, \"w\", newline=\"\", encoding=\"utf-8\"\n",
    "        ) as file:\n",
    "            csv_writer = AsyncDictWriter(file, fieldnames=column_names)\n",
    "            await csv_writer.writeheader()\n",
    "            await csv_writer.writerows(data)\n",
    "        json_file = csv_file.replace(\".csv\", \".json\")\n",
    "        async with aiofiles.open(\n",
    "            json_file, \"w\", encoding=\"utf-8\", newline=\"\\n\"\n",
    "        ) as file:\n",
    "            await file.write(json.dumps(data, indent=4, ensure_ascii=False))\n",
    "    except BaseException:\n",
    "        return\n",
    "\n",
    "\n",
    "async def stop_logging() -> None:\n",
    "    \"\"\"Stop logging.\"\"\"\n",
    "    await asyncio.to_thread(runtime_logging.stop)\n",
    "    if not os.path.exists(\"logs\"):\n",
    "        try:\n",
    "            os.makedirs(\"logs\", exist_ok=True)\n",
    "        except BaseException:\n",
    "            pass\n",
    "    for table in [\n",
    "        \"chat_completions\",\n",
    "        \"agents\",\n",
    "        \"oai_wrappers\",\n",
    "        \"oai_clients\",\n",
    "        \"version\",\n",
    "        \"events\",\n",
    "        \"function_calls\",\n",
    "    ]:\n",
    "        dest = os.path.join(\"logs\", f\"{table}.csv\")\n",
    "        await get_sqlite_out(\"flow.db\", table, dest)\n",
    "\n",
    "\n",
    "def _check_for_extra_agents(agent: ConversableAgent) -> list[ConversableAgent]:\n",
    "    _extra_agents: list[ConversableAgent] = []\n",
    "    _agent_cls_name = agent.__class__.__name__\n",
    "    if _agent_cls_name == \"CaptainAgent\":\n",
    "        _assistant_agent = getattr(agent, \"assistant\", None)\n",
    "        if _assistant_agent and _assistant_agent not in _extra_agents:\n",
    "            _extra_agents.append(_assistant_agent)\n",
    "        _executor_agent = getattr(agent, \"executor\", None)\n",
    "        if _executor_agent and _executor_agent not in _extra_agents:\n",
    "            _extra_agents.append(_executor_agent)\n",
    "    return _extra_agents\n",
    "\n",
    "\n",
    "def _check_for_group_members(agent: ConversableAgent) -> list[ConversableAgent]:\n",
    "    _extra_agents: list[ConversableAgent] = []\n",
    "    _group_chat = getattr(agent, \"_groupchat\", None)\n",
    "    if _group_chat:\n",
    "        _chat_agents = getattr(_group_chat, \"agents\", [])\n",
    "        if isinstance(_chat_agents, list):\n",
    "            for _group_member in _chat_agents:\n",
    "                if _group_member not in _extra_agents:\n",
    "                    _extra_agents.append(_group_member)\n",
    "    _manager = getattr(agent, \"_group_manager\", None)\n",
    "    if _manager:\n",
    "        if _manager not in _extra_agents:\n",
    "            _extra_agents.append(_manager)\n",
    "        for _group_member in _check_for_group_members(_manager):\n",
    "            if _group_member not in _extra_agents:\n",
    "                _extra_agents.append(_group_member)\n",
    "    return _extra_agents\n",
    "\n",
    "\n",
    "def _get_known_agents() -> list[ConversableAgent]:\n",
    "    _known_agents: list[ConversableAgent] = []\n",
    "    if customer_proxy not in _known_agents:\n",
    "        _known_agents.append(customer_proxy)\n",
    "    _known_agents.append(customer_proxy)\n",
    "    for _group_member in _check_for_group_members(customer_proxy):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(customer_proxy):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if customer_engagement_agent not in _known_agents:\n",
    "        _known_agents.append(customer_engagement_agent)\n",
    "    _known_agents.append(customer_engagement_agent)\n",
    "    for _group_member in _check_for_group_members(customer_engagement_agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(customer_engagement_agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if topic_preference_agent not in _known_agents:\n",
    "        _known_agents.append(topic_preference_agent)\n",
    "    _known_agents.append(topic_preference_agent)\n",
    "    for _group_member in _check_for_group_members(topic_preference_agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(topic_preference_agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if personal_information_agent not in _known_agents:\n",
    "        _known_agents.append(personal_information_agent)\n",
    "    _known_agents.append(personal_information_agent)\n",
    "    for _group_member in _check_for_group_members(personal_information_agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(personal_information_agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "    return _known_agents\n",
    "\n",
    "\n",
    "async def store_error(exc: BaseException | None = None) -> None:\n",
    "    \"\"\"Store the error in error.json.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exc : BaseException | None\n",
    "        The exception we got if any.\n",
    "    \"\"\"\n",
    "    reason = (\n",
    "        \"Event handler stopped processing\"\n",
    "        if not exc\n",
    "        else traceback.format_exc()\n",
    "    )\n",
    "    try:\n",
    "        async with aiofiles.open(\n",
    "            \"error.json\", \"w\", encoding=\"utf-8\", newline=\"\\n\"\n",
    "        ) as file:\n",
    "            await file.write(json.dumps({\"error\": reason}))\n",
    "    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "        pass\n",
    "\n",
    "\n",
    "async def store_results(result_dicts: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Store the results to results.json.\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_dicts : list[dict[str, Any]]\n",
    "        The list of the results.\n",
    "    \"\"\"\n",
    "    async with aiofiles.open(\n",
    "        \"results.json\", \"w\", encoding=\"utf-8\", newline=\"\\n\"\n",
    "    ) as file:\n",
    "        await file.write(\n",
    "            json.dumps({'results': result_dicts}, indent=4, ensure_ascii=False)\n",
    "        )\n",
    "\n",
    "\n",
    "def _get_agent_by_name(\n",
    "    agents: list[ConversableAgent], agent_name: str\n",
    ") -> tuple[int, ConversableAgent | None]:\n",
    "    \"\"\"Get an agent by its name.\"\"\"\n",
    "    for ind, agent in enumerate(agents):\n",
    "        if agent.name == agent_name:\n",
    "            return ind, agent\n",
    "    return -1, None\n",
    "\n",
    "\n",
    "def _handle_resume_group_pattern(\n",
    "    detected_pattern: Pattern, state_messages: list[dict[str, Any]]\n",
    ") -> None:\n",
    "    \"\"\"Handle detected pattern for resuming a group chat.\"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements\n",
    "    try:\n",
    "        _pattern_type = getattr(detected_pattern.__class__, \"__name__\", None)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if _pattern_type == \"RoundRobinPattern\" and state_messages:\n",
    "        last_message = state_messages[-1]\n",
    "        if not last_message or not isinstance(last_message, dict):\n",
    "            return\n",
    "        last_agent_name = last_message.get(\"name\", \"\")\n",
    "        if not last_agent_name:\n",
    "            return\n",
    "        try:\n",
    "            idx, last_agent = _get_agent_by_name(\n",
    "                detected_pattern.agents, last_agent_name\n",
    "            )\n",
    "            if last_agent and len(detected_pattern.agents) >= (idx + 1):\n",
    "                detected_pattern.agents.append(detected_pattern.user_agent)\n",
    "                detected_pattern.initial_agent = detected_pattern.agents[\n",
    "                    idx + 1\n",
    "                ]\n",
    "                detected_pattern.user_agent = detected_pattern.agents[idx]\n",
    "                # fmt: off\n",
    "                new_agent_order_list = detected_pattern.agents[idx+1:] + detected_pattern.agents[:idx]\n",
    "                # fmt: on\n",
    "                detected_pattern.agents = new_agent_order_list\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "\n",
    "async def _prepare_resume(state_json: str | Path | None = None) -> None:\n",
    "    \"\"\"Prepare resuming a chat from state.json.\n",
    "\n",
    "    state.json format:\n",
    "        {\n",
    "            \"messages\": [{\"content\": \"..\", \"role\": \"...\", \"name\": \"...\"}],\n",
    "            \"context_variables\": {\"key1\": \"value1\", \"key2\": 4, \"key3\": [], \"key4\": {\"other\": \"key\"}}\n",
    "        }\n",
    "    metadata.json format:\n",
    "        {\n",
    "            \"type\": \"group\",\n",
    "            \"group\": {  # one of:\n",
    "                \"pattern\" : \"<pattern_name>\",\n",
    "                \"manager\" : \"<manager_name>\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state_json : str | Path | None\n",
    "        The path to state.json to load previous state.\n",
    "    \"\"\"\n",
    "    global __INITIAL_MSG__\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements\n",
    "    if not state_json or not Path(state_json).is_file():\n",
    "        return\n",
    "    metadata_json = str(state_json).replace(\"state.json\", \"metadata.json\")\n",
    "    if not metadata_json or not Path(metadata_json).is_file():\n",
    "        return\n",
    "    try:\n",
    "        async with aiofiles.open(metadata_json, \"r\", encoding=\"utf-8\") as f:\n",
    "            f_data = await f.read()\n",
    "            _metadata_dict = json.loads(f_data)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if not _metadata_dict or not isinstance(_metadata_dict, dict):\n",
    "        return\n",
    "    _state_chat_type = _metadata_dict.get(\"type\", \"\")\n",
    "    if _state_chat_type != \"group\":\n",
    "        # only resume group chats\n",
    "        return\n",
    "    _state_group_details = _metadata_dict.get(\"group\", {})\n",
    "    if not _state_group_details or not isinstance(_state_group_details, dict):\n",
    "        return\n",
    "    # either pattern or manager\n",
    "    _state_group_pattern = _state_group_details.get(\"pattern\", \"\")\n",
    "    _state_group_manager = _state_group_details.get(\"manager\", \"\")\n",
    "    if not _state_group_pattern and not _state_group_manager:\n",
    "        return\n",
    "    try:\n",
    "        async with aiofiles.open(state_json, \"r\", encoding=\"utf-8\") as f:\n",
    "            f_data = await f.read()\n",
    "            _state_dict = json.loads(f_data)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if not _state_dict or not isinstance(_state_dict, dict):\n",
    "        return\n",
    "    _state_messages = _state_dict.get(\"context_variables\", [])\n",
    "    _detected_pattern = None\n",
    "    if _state_group_pattern and isinstance(_state_group_pattern, str):\n",
    "        _detected_pattern = __GROUP__[\"patterns\"].get(\n",
    "            _state_group_pattern, None\n",
    "        )\n",
    "        if _detected_pattern:\n",
    "            _state_context_variables = _state_dict.get(\"context_variables\", {})\n",
    "            if _state_context_variables and isinstance(\n",
    "                _state_context_variables, dict\n",
    "            ):\n",
    "                _detected_pattern.context_variables = ContextVariables(\n",
    "                    data=_state_context_variables\n",
    "                )\n",
    "        if _state_messages and isinstance(_state_messages, list):\n",
    "            __INITIAL_MSG__ = _state_messages\n",
    "    elif _state_group_manager and isinstance(_state_group_manager, str):\n",
    "        _known_group_manager = __AGENTS__.get(_state_group_manager, None)\n",
    "        if _known_group_manager and hasattr(_known_group_manager, \"groupchat\"):\n",
    "            if _state_messages and isinstance(_state_messages, list):\n",
    "                _known_group_manager.groupchat.messages = _state_messages\n",
    "        else:\n",
    "            _detected_pattern = __GROUP__[\"patterns\"].get(\n",
    "                f\"{_state_group_manager}_pattern\"\n",
    "            )\n",
    "            if _detected_pattern:\n",
    "                _state_context_variables = _state_dict.get(\n",
    "                    \"context_variables\", {}\n",
    "                )\n",
    "                if _state_context_variables and isinstance(\n",
    "                    _state_context_variables, dict\n",
    "                ):\n",
    "                    _detected_pattern.context_variables = ContextVariables(\n",
    "                        data=_state_context_variables\n",
    "                    )\n",
    "            if _state_messages and isinstance(_state_messages, list):\n",
    "                __INITIAL_MSG__ = _state_messages\n",
    "    if (\n",
    "        _detected_pattern\n",
    "        and _state_messages\n",
    "        and isinstance(_state_messages, list)\n",
    "    ):\n",
    "        _handle_resume_group_pattern(_detected_pattern, _state_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bfbb1b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c94f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "async def main(\n",
    "    on_event: (\n",
    "        Callable[\n",
    "            [BaseEvent, list[ConversableAgent]], Coroutine[None, None, bool]\n",
    "        ]\n",
    "        | None\n",
    "    ) = None,\n",
    "    state_json: str | Path | None = None,\n",
    ") -> list[dict[str, Any]]:\n",
    "    \"\"\"Start chatting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict[str, Any]]\n",
    "        The result of the chat session.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    SystemExit\n",
    "        If the user interrupts the chat session.\n",
    "    \"\"\"\n",
    "    if state_json:\n",
    "        await _prepare_resume(state_json)\n",
    "    results: list[AsyncRunResponseProtocol] | AsyncRunResponseProtocol = []\n",
    "    result_dicts: list[dict[str, Any]] = []\n",
    "    a_pause_event = asyncio.Event()\n",
    "    a_pause_event.set()\n",
    "    pause_event = threading.Event()\n",
    "    pause_event.set()\n",
    "    if Path(\".cache\").is_dir():\n",
    "        shutil.rmtree(\".cache\", ignore_errors=True)\n",
    "    results = await personal_information_agent.a_sequential_run(__INITIAL_MSG__)\n",
    "    if not isinstance(results, list):\n",
    "        results = [results]  # pylint: disable=redefined-variable-type\n",
    "    got_agents = False\n",
    "    known_agents: list[ConversableAgent] = []\n",
    "    result_events: list[dict[str, Any]] = []\n",
    "    if on_event:\n",
    "        for index, result in enumerate(results):\n",
    "            result_events = []\n",
    "            async for event in result.events:\n",
    "                try:\n",
    "                    result_events.append(\n",
    "                        event.model_dump(mode=\"json\", fallback=str)\n",
    "                    )\n",
    "                except BaseException:  # pylint: disable=broad-exception-caught\n",
    "                    pass\n",
    "                if not got_agents:\n",
    "                    known_agents = _get_known_agents()\n",
    "                    got_agents = True\n",
    "                a_pause_event.clear()\n",
    "                try:\n",
    "                    should_continue = await on_event(event, known_agents)\n",
    "                    a_pause_event.set()\n",
    "                except BaseException as e:\n",
    "                    await stop_logging()\n",
    "                    await store_error(e)\n",
    "                    raise SystemExit(\"Error in event handler: \" + str(e)) from e\n",
    "                if getattr(event, \"type\") == \"run_completion\":\n",
    "                    break\n",
    "                if not should_continue:\n",
    "                    await stop_logging()\n",
    "                    await store_error()\n",
    "                    raise SystemExit(\"Event handler stopped processing\")\n",
    "            result_cost = await result.cost\n",
    "            result_context_variables = await result.context_variables\n",
    "            result_dict = {\n",
    "                \"index\": index,\n",
    "                \"uuid\": str(result.uuid),\n",
    "                \"events\": result_events,\n",
    "                \"messages\": await result.messages,\n",
    "                \"summary\": await result.summary,\n",
    "                \"cost\": (\n",
    "                    result_cost.model_dump(mode=\"json\", fallback=str)\n",
    "                    if result_cost\n",
    "                    else None\n",
    "                ),\n",
    "                \"context_variables\": (\n",
    "                    result_context_variables.model_dump(\n",
    "                        mode=\"json\", fallback=str\n",
    "                    )\n",
    "                    if result_context_variables\n",
    "                    else None\n",
    "                ),\n",
    "                \"last_speaker\": await result.last_speaker,\n",
    "            }\n",
    "            result_dicts.append(result_dict)\n",
    "    else:\n",
    "        for index, result in enumerate(results):\n",
    "            result_events = []\n",
    "            # await result.process()\n",
    "            async for event in result.events:\n",
    "                try:\n",
    "                    result_events.append(\n",
    "                        event.model_dump(mode=\"json\", fallback=str)\n",
    "                    )\n",
    "                except BaseException:  # pylint: disable=broad-exception-caught\n",
    "                    pass\n",
    "            result_cost = await result.cost\n",
    "            result_context_variables = await result.context_variables\n",
    "            result_dict = {\n",
    "                \"index\": index,\n",
    "                \"uuid\": str(result.uuid),\n",
    "                \"events\": result_events,\n",
    "                \"messages\": await result.messages,\n",
    "                \"summary\": await result.summary,\n",
    "                \"cost\": (\n",
    "                    result_cost.model_dump(mode=\"json\", fallback=str)\n",
    "                    if result_cost\n",
    "                    else None\n",
    "                ),\n",
    "                \"context_variables\": (\n",
    "                    result_context_variables.model_dump(\n",
    "                        mode=\"json\", fallback=str\n",
    "                    )\n",
    "                    if result_context_variables\n",
    "                    else None\n",
    "                ),\n",
    "                \"last_speaker\": await result.last_speaker,\n",
    "            }\n",
    "            result_dicts.append(result_dict)\n",
    "\n",
    "    await stop_logging()\n",
    "    await store_results(result_dicts)\n",
    "    return result_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "await main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": false,
   "hide_notebook_metadata": true,
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
