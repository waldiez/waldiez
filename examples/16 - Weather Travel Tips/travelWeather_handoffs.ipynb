{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0df116",
   "metadata": {},
   "source": [
    "# Name: Weather sightseeing recommendation\n",
    "\n",
    "## Description: A group chat workflow checking whether the weather conditions are fine for visiting a specified site at a specified date. It contains an agent using tool to retrieve the temperature at real-time. The communication within the agents is achieved using handoffs.\n",
    "\n",
    "## Tags: Weather, Travel, Group\n",
    "\n",
    "###ðŸ§© generated with â¤ï¸ by Waldiez.\n",
    "\n",
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d128ff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# # !{sys.executable} -m pip install -q ag2[openai]==0.10.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06083ce0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974d7b3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import csv\n",
    "import importlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "import sys\n",
    "import threading\n",
    "import traceback\n",
    "from dataclasses import asdict\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from types import ModuleType\n",
    "from typing import (\n",
    "    Annotated,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Coroutine,\n",
    "    Dict,\n",
    "    List,\n",
    "    Optional,\n",
    "    Set,\n",
    "    Tuple,\n",
    "    TypedDict,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "import autogen  # type: ignore\n",
    "from autogen import (\n",
    "    Agent,\n",
    "    Cache,\n",
    "    ChatResult,\n",
    "    ConversableAgent,\n",
    "    GroupChat,\n",
    "    UpdateSystemMessage,\n",
    "    UserProxyAgent,\n",
    "    register_function,\n",
    "    runtime_logging,\n",
    ")\n",
    "from autogen.agentchat import GroupChatManager, ReplyResult, run_group_chat\n",
    "from autogen.agentchat.group import (\n",
    "    AgentTarget,\n",
    "    ContextVariables,\n",
    "    OnCondition,\n",
    "    OnContextCondition,\n",
    "    ReplyResult,\n",
    "    RevertToUserTarget,\n",
    "    StringContextCondition,\n",
    "    StringLLMCondition,\n",
    ")\n",
    "from autogen.agentchat.group.patterns import DefaultPattern\n",
    "from autogen.agentchat.group.patterns.pattern import Pattern\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "from autogen.events import BaseEvent\n",
    "from autogen.io.run_response import (\n",
    "    AsyncRunResponseProtocol,\n",
    "    RunResponseProtocol,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Common environment variable setup for Waldiez flows\n",
    "load_dotenv(override=True)\n",
    "os.environ[\"AUTOGEN_USE_DOCKER\"] = \"0\"\n",
    "os.environ[\"TOGETHER_NO_BANNER\"] = \"1\"\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"False\"\n",
    "#\n",
    "# let's try to avoid:\n",
    "# module 'numpy' has no attribute '_no_nep50_warning'\"\n",
    "# ref: https://github.com/numpy/numpy/blob/v2.2.2/doc/source/release/2.2.0-notes.rst#nep-50-promotion-state-option-removed\n",
    "os.environ[\"NEP50_DEPRECATION_WARNING\"] = \"0\"\n",
    "os.environ[\"NEP50_DISABLE_WARNING\"] = \"1\"\n",
    "os.environ[\"NPY_PROMOTION_STATE\"] = \"weak\"\n",
    "if not hasattr(np, \"_no_pep50_warning\"):\n",
    "\n",
    "    import contextlib\n",
    "    from typing import Generator\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _np_no_nep50_warning() -> Generator[None, None, None]:\n",
    "        \"\"\"Dummy function to avoid the warning.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        None\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "        yield\n",
    "\n",
    "    setattr(np, \"_no_pep50_warning\", _np_no_nep50_warning)  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5eb756",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fe64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_logging() -> None:\n",
    "    \"\"\"Start logging.\"\"\"\n",
    "    runtime_logging.start(\n",
    "        logger_type=\"sqlite\",\n",
    "        config={\"dbname\": \"flow.db\"},\n",
    "    )\n",
    "\n",
    "\n",
    "start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1143bf5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Load model API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# This section assumes that a file named:\n",
    "# \"weather_sightseeing_api_keys.py\"\n",
    "# exists in the same directory as this file.\n",
    "# This file contains the API keys for the models used in this flow.\n",
    "# It should be .gitignored and not shared publicly.\n",
    "# If this file is not present, you can either create it manually\n",
    "# or change the way API keys are loaded in the flow.\n",
    "\n",
    "\n",
    "def load_api_key_module(flow_name: str) -> ModuleType:\n",
    "    \"\"\"Load the api key module.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flow_name : str\n",
    "        The flow name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ModuleType\n",
    "        The api keys loading module.\n",
    "    \"\"\"\n",
    "    module_name = f\"{flow_name}_api_keys\"\n",
    "    if module_name in sys.modules:\n",
    "        return importlib.reload(sys.modules[module_name])\n",
    "    return importlib.import_module(module_name)\n",
    "\n",
    "\n",
    "__MODELS_MODULE__ = load_api_key_module(\"weather_sightseeing\")\n",
    "\n",
    "\n",
    "def get_weather_sightseeing_model_api_key(model_name: str) -> str:\n",
    "    \"\"\"Get the model api key.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        The model name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The model api key.\n",
    "    \"\"\"\n",
    "    return __MODELS_MODULE__.get_weather_sightseeing_model_api_key(model_name)\n",
    "\n",
    "\n",
    "class GroupDict(TypedDict):\n",
    "    \"\"\"Group related global dict.\"\"\"\n",
    "\n",
    "    chats: dict[str, GroupChat]\n",
    "    patterns: dict[str, Pattern]\n",
    "\n",
    "\n",
    "__GROUP__: GroupDict = {\"chats\": {}, \"patterns\": {}}\n",
    "\n",
    "__AGENTS__: dict[str, ConversableAgent] = {}\n",
    "\n",
    "__CACHE_SEED__: int | None = None\n",
    "\n",
    "__IS_WAAT__: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe2a54e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3745e1e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def record_info(\n",
    "    date: str, time: str, city: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Record the date, time and city in the workflow context\"\"\"\n",
    "\n",
    "    context_variables[\"date\"] = date\n",
    "    context_variables[\"definedDate\"] = True\n",
    "    context_variables[\"time\"] = time\n",
    "    context_variables[\"definedTime\"] = True\n",
    "    context_variables[\"city\"] = city\n",
    "    context_variables[\"definedCity\"] = True\n",
    "    context_variables[\"retrievedInfo\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        context_variables=context_variables,\n",
    "        message=f\"Info Recorded: {date}, {time} and {city}\",\n",
    "    )\n",
    "\n",
    "\n",
    "def record_temperature(context_variables: ContextVariables) -> ReplyResult:\n",
    "    \"\"\"Record the place in the workflow context\"\"\"\n",
    "\n",
    "    place = context_variables[\"city\"]\n",
    "    target_time = context_variables[\"time\"]\n",
    "    target_date_str = context_variables[\"date\"]\n",
    "\n",
    "    try:\n",
    "        # Use pandas to parse date and time flexibly\n",
    "        datetime_str = f\"{target_date_str} {target_time}\"\n",
    "        dt = pd.to_datetime(\n",
    "            datetime_str, dayfirst=True\n",
    "        )  # dayfirst=True handles DD/MM/YYYY\n",
    "        hour = dt.hour\n",
    "        remainder = hour % 3\n",
    "        if remainder < 1.5:\n",
    "            rounded_hour = hour - remainder\n",
    "        else:\n",
    "            rounded_hour = hour + (3 - remainder)\n",
    "            if rounded_hour >= 24:\n",
    "                dt += timedelta(days=1)\n",
    "                rounded_hour = 0\n",
    "        dt = dt.replace(hour=rounded_hour, minute=0, second=0, microsecond=0)\n",
    "\n",
    "        # Format inputs for API\n",
    "        place = place.strip()\n",
    "        formatted_date = dt.strftime('%Y-%m-%d')\n",
    "        formatted_time = str(dt.hour * 100)\n",
    "\n",
    "        print(\n",
    "            f\"Searching for weather in {place} on {formatted_date} at {dt.hour:02d}:00...\"\n",
    "        )\n",
    "\n",
    "        # Get weather data\n",
    "        response = requests.get(f\"https://wttr.in/{place}?format=j1\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Search for the target date and time\n",
    "        forecast = None\n",
    "        for day in data['weather']:\n",
    "            if day['date'] == formatted_date:\n",
    "                for slot in day['hourly']:\n",
    "                    if slot['time'] == formatted_time:\n",
    "                        forecast = slot\n",
    "                        break\n",
    "                break\n",
    "\n",
    "        # Output result\n",
    "        if forecast:\n",
    "            temp_c = forecast['tempC']\n",
    "            feels_like = forecast['FeelsLikeC']\n",
    "            desc = forecast['weatherDesc'][0]['value']\n",
    "            print(\n",
    "                f\"\\nWeather in {place} on {formatted_date} at {dt.hour:02d}:00:\"\n",
    "            )\n",
    "            print(f\"Temperature: {temp_c}Â°C, Feels like: {feels_like}Â°C\")\n",
    "            print(f\"Conditions: {desc}\")\n",
    "            context_variables[\"definedTemperature\"] = True\n",
    "            context_variables[\"temperature\"] = temp_c\n",
    "        else:\n",
    "            print(\n",
    "                f\"\\nSorry, could not find the forecast for {place} on {formatted_date} at {dt.hour:02d}:00.\"\n",
    "            )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\n",
    "            \"Try formats like: '27/06/2025 2PM', '2025-06-27 14:00', 'June 27, 2025 2:30 PM'\"\n",
    "        )\n",
    "\n",
    "    return ReplyResult(\n",
    "        context_variables=context_variables,\n",
    "        message=f\"Temperature Recorded: {temp_c}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6fe175",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_1_llm_config: dict[str, Any] = {\n",
    "    \"model\": \"gpt-4.1\",\n",
    "    \"api_type\": \"openai\",\n",
    "    \"api_key\": get_weather_sightseeing_model_api_key(\"gpt_4_1\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c980d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "Info_Agent_executor = LocalCommandLineCodeExecutor(\n",
    "    work_dir=\"coding\",\n",
    ")\n",
    "\n",
    "Info_Agent = ConversableAgent(\n",
    "    name=\"Info_Agent\",\n",
    "    description=\"A place agent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config={\"executor\": Info_Agent_executor},\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        record_info,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[\n",
    "        UpdateSystemMessage(\n",
    "            \"You need to retrieve the city the date and the time\"\n",
    "        ),\n",
    "    ],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_1_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"Info_Agent\"] = Info_Agent\n",
    "\n",
    "Triage_Agent = ConversableAgent(\n",
    "    name=\"Triage_Agent\",\n",
    "    description=\"triage_agent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[],\n",
    "    update_agent_state_before_reply=[\n",
    "        UpdateSystemMessage(\n",
    "            \"You are an order triage agent, working with a user and a group of agents to provide support for your weather tips.\\n Give the speech to Info_Agent if the user hasn't defined a place.\\nThe Weather_Agent will retrieve all weather related tasks. \\nYou will manage all weather optimization task related tasks. Be sure to the temperature value first. Then if it's valid you can record it in the context.\\n\\nAsk the user for further information when necessary.\\n\\nThe current status of this workflow is:\\nCity of interest: {city}\\nCity defined: {definedCity}\\nTime: {time}\\nTime defined: {definedTime}\\nDate: {date}\\nTemperature: {temperature}\"\n",
    "        ),\n",
    "    ],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_1_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"Triage_Agent\"] = Triage_Agent\n",
    "\n",
    "User = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    description=\"A new User agent\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    llm_config=False,\n",
    ")\n",
    "\n",
    "__AGENTS__[\"User\"] = User\n",
    "\n",
    "Weather_Agent = ConversableAgent(\n",
    "    name=\"Weather_Agent\",\n",
    "    description=\"weather_agent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        record_temperature,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[\n",
    "        UpdateSystemMessage(\n",
    "            \"You are a weather agent, get temperature data. Check weather the temperature values are safe for the user.\\nReturn to the triage_agent if temp is retrieved. \\n\"\n",
    "        ),\n",
    "    ],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_1_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"Weather_Agent\"] = Weather_Agent\n",
    "\n",
    "Info_Agent.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=AgentTarget(Triage_Agent),\n",
    "        condition=StringLLMCondition(prompt=\"The info have been retrieved\"),\n",
    "    )\n",
    ")\n",
    "Info_Agent.handoffs.set_after_work(target=RevertToUserTarget())\n",
    "\n",
    "Triage_Agent.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=AgentTarget(Info_Agent),\n",
    "        condition=StringLLMCondition(\n",
    "            prompt=\"The user hasn't defined a city, ask for the place of interest\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "Triage_Agent.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=AgentTarget(Weather_Agent),\n",
    "        condition=StringLLMCondition(\n",
    "            prompt=\"Temperature has not been retrieved\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "Triage_Agent.handoffs.set_after_work(target=RevertToUserTarget())\n",
    "\n",
    "Weather_Agent.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(Triage_Agent),\n",
    "        condition=StringContextCondition(variable_name=\"{definedTemperature}\"),\n",
    "    )\n",
    ")\n",
    "Weather_Agent.handoffs.set_after_work(target=AgentTarget(Triage_Agent))\n",
    "\n",
    "__INITIAL_MSG__ = \"Hi I want to visit a place\"\n",
    "\n",
    "_pattern = DefaultPattern(\n",
    "    initial_agent=Triage_Agent,\n",
    "    agents=[Weather_Agent, Info_Agent, Triage_Agent],\n",
    "    user_agent=User,\n",
    "    group_manager_args={\n",
    "        \"llm_config\": False,\n",
    "        \"name\": \"\",\n",
    "    },\n",
    "    context_variables=ContextVariables(\n",
    "        data={\n",
    "            \"timestamp\": None,\n",
    "            \"temperature\": None,\n",
    "            \"city\": None,\n",
    "            \"definedCity\": False,\n",
    "            \"date\": None,\n",
    "            \"definedTime\": False,\n",
    "            \"definedDate\": False,\n",
    "            \"time\": None,\n",
    "            \"retrievedInfo\": False,\n",
    "            \"definedTemperature\": False,\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "__GROUP__[\"patterns\"][\"_pattern\"] = _pattern\n",
    "\n",
    "\n",
    "def get_sqlite_out(dbname: str, table: str, csv_file: str) -> None:\n",
    "    \"\"\"Convert a sqlite table to csv and json files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dbname : str\n",
    "        The sqlite database name.\n",
    "    table : str\n",
    "        The table name.\n",
    "    csv_file : str\n",
    "        The csv file name.\n",
    "    \"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements\n",
    "    try:\n",
    "        conn = sqlite3.connect(dbname)\n",
    "    except BaseException:\n",
    "        return\n",
    "    query = f\"SELECT * FROM {table}\"  # nosec\n",
    "    try:\n",
    "        cursor = conn.execute(query)\n",
    "    except BaseException:\n",
    "        conn.close()\n",
    "        return\n",
    "    try:\n",
    "        rows = cursor.fetchall()\n",
    "        column_names = [description[0] for description in cursor.description]\n",
    "        data = [dict(zip(column_names, row, strict=True)) for row in rows]\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    except BaseException:\n",
    "        try:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "        except BaseException:\n",
    "            pass\n",
    "        return\n",
    "    try:\n",
    "        with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            csv_writer = csv.DictWriter(file, fieldnames=column_names)\n",
    "            csv_writer.writeheader()\n",
    "            csv_writer.writerows(data)\n",
    "        json_file = csv_file.replace(\".csv\", \".json\")\n",
    "        with open(json_file, \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "            json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "    except BaseException:\n",
    "        return\n",
    "\n",
    "\n",
    "def stop_logging() -> None:\n",
    "    \"\"\"Stop logging.\"\"\"\n",
    "    if not __IS_WAAT__:\n",
    "        runtime_logging.stop()\n",
    "        if not os.path.exists(\"logs\"):\n",
    "            try:\n",
    "                os.makedirs(\"logs\", exist_ok=True)\n",
    "            except BaseException:\n",
    "                pass\n",
    "        for table in [\n",
    "            \"chat_completions\",\n",
    "            \"agents\",\n",
    "            \"oai_wrappers\",\n",
    "            \"oai_clients\",\n",
    "            \"version\",\n",
    "            \"events\",\n",
    "            \"function_calls\",\n",
    "        ]:\n",
    "            dest = os.path.join(\"logs\", f\"{table}.csv\")\n",
    "            get_sqlite_out(\"flow.db\", table, dest)\n",
    "\n",
    "\n",
    "def _check_for_extra_agents(agent: ConversableAgent) -> list[ConversableAgent]:\n",
    "    _extra_agents: list[ConversableAgent] = []\n",
    "    _agent_cls_name = agent.__class__.__name__\n",
    "    if _agent_cls_name == \"CaptainAgent\":\n",
    "        _assistant_agent = getattr(agent, \"assistant\", None)\n",
    "        if _assistant_agent and _assistant_agent not in _extra_agents:\n",
    "            _extra_agents.append(_assistant_agent)\n",
    "        _executor_agent = getattr(agent, \"executor\", None)\n",
    "        if _executor_agent and _executor_agent not in _extra_agents:\n",
    "            _extra_agents.append(_executor_agent)\n",
    "    return _extra_agents\n",
    "\n",
    "\n",
    "def _check_for_group_members(agent: ConversableAgent) -> list[ConversableAgent]:\n",
    "    _extra_agents: list[ConversableAgent] = []\n",
    "    _group_chat = getattr(agent, \"_groupchat\", None)\n",
    "    if _group_chat:\n",
    "        _chat_agents = getattr(_group_chat, \"agents\", [])\n",
    "        if isinstance(_chat_agents, list):\n",
    "            for _group_member in _chat_agents:\n",
    "                if _group_member not in _extra_agents:\n",
    "                    _extra_agents.append(_group_member)\n",
    "    _manager = getattr(agent, \"_group_manager\", None)\n",
    "    if _manager:\n",
    "        if _manager not in _extra_agents:\n",
    "            _extra_agents.append(_manager)\n",
    "        for _group_member in _check_for_group_members(_manager):\n",
    "            if _group_member not in _extra_agents:\n",
    "                _extra_agents.append(_group_member)\n",
    "    return _extra_agents\n",
    "\n",
    "\n",
    "def _get_known_agents() -> list[ConversableAgent]:\n",
    "    _known_agents: list[ConversableAgent] = []\n",
    "    if User not in _known_agents:\n",
    "        _known_agents.append(User)\n",
    "    _known_agents.append(User)\n",
    "    for _group_member in _check_for_group_members(User):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(User):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if Weather_Agent not in _known_agents:\n",
    "        _known_agents.append(Weather_Agent)\n",
    "    _known_agents.append(Weather_Agent)\n",
    "    for _group_member in _check_for_group_members(Weather_Agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(Weather_Agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if Info_Agent not in _known_agents:\n",
    "        _known_agents.append(Info_Agent)\n",
    "    _known_agents.append(Info_Agent)\n",
    "    for _group_member in _check_for_group_members(Info_Agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(Info_Agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if Triage_Agent not in _known_agents:\n",
    "        _known_agents.append(Triage_Agent)\n",
    "    _known_agents.append(Triage_Agent)\n",
    "    for _group_member in _check_for_group_members(Triage_Agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(Triage_Agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "    return _known_agents\n",
    "\n",
    "\n",
    "def store_error(exc: BaseException | None = None) -> None:\n",
    "    \"\"\"Store the error in error.json.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exc : BaseException | None\n",
    "        The exception we got if any.\n",
    "    \"\"\"\n",
    "    reason = (\n",
    "        \"Event handler stopped processing\"\n",
    "        if not exc\n",
    "        else traceback.format_exc()\n",
    "    )\n",
    "    try:\n",
    "        with open(\"error.json\", \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "            file.write(json.dumps({\"error\": reason}))\n",
    "    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "        pass\n",
    "\n",
    "\n",
    "def store_results(result_dicts: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Store the results to results.json.\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_dicts : list[dict[str, Any]]\n",
    "        The list of the results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(\"results.json\", \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "            file.write(\n",
    "                json.dumps(\n",
    "                    {'results': result_dicts}, indent=4, ensure_ascii=False\n",
    "                )\n",
    "            )\n",
    "    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "        pass\n",
    "\n",
    "\n",
    "def _get_agent_by_name(\n",
    "    agents: list[ConversableAgent], agent_name: str\n",
    ") -> tuple[int, ConversableAgent | None]:\n",
    "    \"\"\"Get an agent by its name.\"\"\"\n",
    "    for ind, agent in enumerate(agents):\n",
    "        if agent.name == agent_name:\n",
    "            return ind, agent\n",
    "    return -1, None\n",
    "\n",
    "\n",
    "def _handle_resume_group_pattern(\n",
    "    detected_pattern: Pattern, state_messages: list[dict[str, Any]]\n",
    ") -> None:\n",
    "    \"\"\"Handle detected pattern for resuming a group chat.\"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements\n",
    "    try:\n",
    "        _pattern_type = getattr(detected_pattern.__class__, \"__name__\", None)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if _pattern_type == \"RoundRobinPattern\" and state_messages:\n",
    "        last_message = state_messages[-1]\n",
    "        if not last_message or not isinstance(last_message, dict):\n",
    "            return\n",
    "        last_agent_name = last_message.get(\"name\", \"\")\n",
    "        if not last_agent_name:\n",
    "            return\n",
    "        try:\n",
    "            idx, last_agent = _get_agent_by_name(\n",
    "                detected_pattern.agents, last_agent_name\n",
    "            )\n",
    "            if last_agent and len(detected_pattern.agents) >= (idx + 1):\n",
    "                detected_pattern.agents.append(detected_pattern.user_agent)\n",
    "                detected_pattern.initial_agent = detected_pattern.agents[\n",
    "                    idx + 1\n",
    "                ]\n",
    "                detected_pattern.user_agent = detected_pattern.agents[idx]\n",
    "                # fmt: off\n",
    "                new_agent_order_list = detected_pattern.agents[idx+1:] + detected_pattern.agents[:idx]\n",
    "                # fmt: on\n",
    "                detected_pattern.agents = new_agent_order_list\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "\n",
    "def _prepare_resume(state_json: str | Path | None = None) -> None:\n",
    "    \"\"\"Prepare resuming a chat from state.json.\n",
    "\n",
    "    state.json format:\n",
    "        {\n",
    "            \"messages\": [{\"content\": \"..\", \"role\": \"...\", \"name\": \"...\"}],\n",
    "            \"context_variables\": {\"key1\": \"value1\", \"key2\": 4, \"key3\": [], \"key4\": {\"other\": \"key\"}}\n",
    "        }\n",
    "    metadata.json format:\n",
    "        {\n",
    "            \"type\": \"group\",\n",
    "            \"group\": {  # one of:\n",
    "                \"pattern\" : \"<pattern_name>\",\n",
    "                \"manager\" : \"<manager_name>\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state_json : str | Path | None\n",
    "        The path to state.json to load previous state.\n",
    "    \"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements,global-statement\n",
    "    global __INITIAL_MSG__\n",
    "    if not state_json or not Path(state_json).is_file():\n",
    "        return\n",
    "    metadata_json = str(state_json).replace(\"state.json\", \"metadata.json\")\n",
    "    if not metadata_json or not Path(metadata_json).is_file():\n",
    "        return\n",
    "    try:\n",
    "        with open(metadata_json, \"r\", encoding=\"utf-8\") as f:\n",
    "            _metadata_dict = json.load(f)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if not _metadata_dict or not isinstance(_metadata_dict, dict):\n",
    "        return\n",
    "    _state_chat_type = _metadata_dict.get(\"type\", \"\")\n",
    "    if _state_chat_type != \"group\":\n",
    "        # only resume group chats\n",
    "        return\n",
    "    _state_group_details = _metadata_dict.get(\"group\", {})\n",
    "    if not _state_group_details or not isinstance(_state_group_details, dict):\n",
    "        return\n",
    "    # either pattern or manager\n",
    "    _state_group_pattern = _state_group_details.get(\"pattern\", \"\")\n",
    "    _state_group_manager = _state_group_details.get(\"manager\", \"\")\n",
    "    if not _state_group_pattern and not _state_group_manager:\n",
    "        return\n",
    "    try:\n",
    "        with open(state_json, \"r\", encoding=\"utf-8\") as f:\n",
    "            _state_dict = json.load(f)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if not _state_dict or not isinstance(_state_dict, dict):\n",
    "        return\n",
    "    _state_messages = _state_dict.get(\"messages\", [])\n",
    "    _detected_pattern = None\n",
    "    if _state_group_pattern and isinstance(_state_group_pattern, str):\n",
    "        _detected_pattern = __GROUP__[\"patterns\"].get(\n",
    "            _state_group_pattern, None\n",
    "        )\n",
    "        if _detected_pattern:\n",
    "            _state_context_variables = _state_dict.get(\"context_variables\", {})\n",
    "            if _state_context_variables and isinstance(\n",
    "                _state_context_variables, dict\n",
    "            ):\n",
    "                _new_context_variables = (\n",
    "                    _detected_pattern.context_variables.data.copy()\n",
    "                )\n",
    "                _new_context_variables.update(_state_context_variables)\n",
    "                _detected_pattern.context_variables = ContextVariables(\n",
    "                    data=_new_context_variables\n",
    "                )\n",
    "        if _state_messages and isinstance(_state_messages, list):\n",
    "            __INITIAL_MSG__ = _state_messages\n",
    "    elif _state_group_manager and isinstance(_state_group_manager, str):\n",
    "        _known_group_manager = __AGENTS__.get(_state_group_manager, None)\n",
    "        if _known_group_manager and hasattr(_known_group_manager, \"groupchat\"):\n",
    "            if _state_messages and isinstance(_state_messages, list):\n",
    "                _known_group_manager.groupchat.messages = _state_messages\n",
    "        else:\n",
    "            _detected_pattern = __GROUP__[\"patterns\"].get(\n",
    "                f\"{_state_group_manager}_pattern\"\n",
    "            )\n",
    "            if _detected_pattern:\n",
    "                _state_context_variables = _state_dict.get(\n",
    "                    \"context_variables\", {}\n",
    "                )\n",
    "                if _state_context_variables and isinstance(\n",
    "                    _state_context_variables, dict\n",
    "                ):\n",
    "                    _new_context_variables = (\n",
    "                        _detected_pattern.context_variables.data.copy()\n",
    "                    )\n",
    "                    _new_context_variables.update(_state_context_variables)\n",
    "                    _detected_pattern.context_variables = ContextVariables(\n",
    "                        data=_new_context_variables\n",
    "                    )\n",
    "            if _state_messages and isinstance(_state_messages, list):\n",
    "                __INITIAL_MSG__ = _state_messages\n",
    "    if (\n",
    "        _detected_pattern\n",
    "        and _state_messages\n",
    "        and isinstance(_state_messages, list)\n",
    "    ):\n",
    "        _handle_resume_group_pattern(_detected_pattern, _state_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e5c58",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd998c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main(\n",
    "    on_event: Callable[[BaseEvent, list[ConversableAgent]], bool] | None = None,\n",
    "    state_json: str | Path | None = None,\n",
    ") -> list[dict[str, Any]]:\n",
    "    \"\"\"Start chatting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict[str, Any]]\n",
    "        The result of the chat session.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    SystemExit\n",
    "        If the user interrupts the chat session.\n",
    "    \"\"\"\n",
    "    if state_json:\n",
    "        _prepare_resume(state_json)\n",
    "    results: list[RunResponseProtocol] | RunResponseProtocol = []\n",
    "    result_dicts: list[dict[str, Any]] = []\n",
    "    a_pause_event = asyncio.Event()\n",
    "    a_pause_event.set()\n",
    "    pause_event = threading.Event()\n",
    "    pause_event.set()\n",
    "    if Path(\".cache\").is_dir():\n",
    "        shutil.rmtree(\".cache\", ignore_errors=True)\n",
    "    results = run_group_chat(\n",
    "        pattern=_pattern,\n",
    "        messages=__INITIAL_MSG__,\n",
    "        max_rounds=40,\n",
    "        pause_event=pause_event,\n",
    "    )\n",
    "    if not isinstance(results, list):\n",
    "        results = [results]  # pylint: disable=redefined-variable-type\n",
    "    got_agents = False\n",
    "    known_agents: list[ConversableAgent] = []\n",
    "    result_events: list[dict[str, Any]] = []\n",
    "    if on_event:\n",
    "        for index, result in enumerate(results):\n",
    "            result_events = []\n",
    "            for event in result.events:\n",
    "                try:\n",
    "                    result_events.append(\n",
    "                        event.model_dump(mode=\"json\", fallback=str)\n",
    "                    )\n",
    "                except BaseException:  # pylint: disable=broad-exception-caught\n",
    "                    pass\n",
    "                if not got_agents:\n",
    "                    known_agents = _get_known_agents()\n",
    "                    got_agents = True\n",
    "                pause_event.clear()\n",
    "                try:\n",
    "                    should_continue = on_event(event, known_agents)\n",
    "                    pause_event.set()\n",
    "                except BaseException as e:\n",
    "                    stop_logging()\n",
    "                    store_error(e)\n",
    "                    raise SystemExit(\"Error in event handler: \" + str(e)) from e\n",
    "                if getattr(event, \"type\") == \"run_completion\":\n",
    "                    break\n",
    "                if not should_continue:\n",
    "                    stop_logging()\n",
    "                    store_error()\n",
    "                    raise SystemExit(\"Event handler stopped processing\")\n",
    "            result_cost = result.cost\n",
    "            result_context_variables = result.context_variables\n",
    "            result_dict = {\n",
    "                \"index\": index,\n",
    "                \"uuid\": str(result.uuid),\n",
    "                \"events\": result_events,\n",
    "                \"messages\": result.messages,\n",
    "                \"summary\": result.summary,\n",
    "                \"cost\": (\n",
    "                    result_cost.model_dump(mode=\"json\", fallback=str)\n",
    "                    if result_cost\n",
    "                    else None\n",
    "                ),\n",
    "                \"context_variables\": (\n",
    "                    result_context_variables.model_dump(\n",
    "                        mode=\"json\", fallback=str\n",
    "                    )\n",
    "                    if result_context_variables\n",
    "                    else None\n",
    "                ),\n",
    "                \"last_speaker\": result.last_speaker,\n",
    "            }\n",
    "            result_dicts.append(result_dict)\n",
    "    else:\n",
    "        for index, result in enumerate(results):\n",
    "            result_events = []\n",
    "            # result.process()\n",
    "            for event in result.events:\n",
    "                try:\n",
    "                    result_events.append(\n",
    "                        event.model_dump(mode=\"json\", fallback=str)\n",
    "                    )\n",
    "                except BaseException:  # pylint: disable=broad-exception-caught\n",
    "                    pass\n",
    "            result_cost = result.cost\n",
    "            result_context_variables = result.context_variables\n",
    "            result_dict = {\n",
    "                \"index\": index,\n",
    "                \"uuid\": str(result.uuid),\n",
    "                \"events\": result_events,\n",
    "                \"messages\": result.messages,\n",
    "                \"summary\": result.summary,\n",
    "                \"cost\": (\n",
    "                    result_cost.model_dump(mode=\"json\", fallback=str)\n",
    "                    if result_cost\n",
    "                    else None\n",
    "                ),\n",
    "                \"context_variables\": (\n",
    "                    result_context_variables.model_dump(\n",
    "                        mode=\"json\", fallback=str\n",
    "                    )\n",
    "                    if result_context_variables\n",
    "                    else None\n",
    "                ),\n",
    "                \"last_speaker\": result.last_speaker,\n",
    "            }\n",
    "            result_dicts.append(result_dict)\n",
    "\n",
    "    stop_logging()\n",
    "    store_results(result_dicts)\n",
    "    return result_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": false,
   "hide_notebook_metadata": true,
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
