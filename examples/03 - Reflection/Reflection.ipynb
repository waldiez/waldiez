{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f433da",
   "metadata": {},
   "source": [
    "# Name: Reflection\n",
    "\n",
    "## Description: Reflection and Blog post Writing\n",
    "\n",
    "## Tags: Reflection, Blog post\n",
    "\n",
    "###ðŸ§© generated with â¤ï¸ by Waldiez.\n",
    "\n",
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d60be",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys  # pyright: ignore\n",
    "\n",
    "# # !{sys.executable} -m pip install -q ag2[openai]==0.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e12a14",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec35cb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# pyright: reportUnusedImport=false,reportMissingTypeStubs=false\n",
    "import csv\n",
    "import importlib\n",
    "import json\n",
    "import os\n",
    "import sqlite3\n",
    "import sys\n",
    "from dataclasses import asdict\n",
    "from pprint import pprint\n",
    "from types import ModuleType\n",
    "from typing import (\n",
    "    Annotated,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    List,\n",
    "    Optional,\n",
    "    Set,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "import autogen  # type: ignore\n",
    "from autogen import (\n",
    "    Agent,\n",
    "    AssistantAgent,\n",
    "    Cache,\n",
    "    ChatResult,\n",
    "    ConversableAgent,\n",
    "    GroupChat,\n",
    "    runtime_logging,\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "# let's try to avoid:\n",
    "# module 'numpy' has no attribute '_no_nep50_warning'\"\n",
    "# ref: https://github.com/numpy/numpy/blob/v2.2.2/doc/source/release/2.2.0-notes.rst#nep-50-promotion-state-option-removed\n",
    "os.environ[\"NEP50_DEPRECATION_WARNING\"] = \"0\"\n",
    "os.environ[\"NEP50_DISABLE_WARNING\"] = \"1\"\n",
    "os.environ[\"NPY_PROMOTION_STATE\"] = \"weak\"\n",
    "if not hasattr(np, \"_no_pep50_warning\"):\n",
    "\n",
    "    import contextlib\n",
    "    from typing import Generator\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _np_no_nep50_warning() -> Generator[None, None, None]:\n",
    "        \"\"\"Dummy function to avoid the warning.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        None\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "        yield\n",
    "\n",
    "    setattr(np, \"_no_pep50_warning\", _np_no_nep50_warning)  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c466b5d9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e80cd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def start_logging() -> None:\n",
    "    \"\"\"Start logging.\"\"\"\n",
    "    runtime_logging.start(\n",
    "        logger_type=\"sqlite\",\n",
    "        config={\"dbname\": \"flow.db\"},\n",
    "    )\n",
    "\n",
    "\n",
    "start_logging()\n",
    "\n",
    "# patch the default IOStream\n",
    "# pylint: disable=import-outside-toplevel\n",
    "from waldiez.running.patch_io_stream import patch_io_stream\n",
    "\n",
    "patch_io_stream(is_async=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c0642f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Load model API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ed22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# This section assumes that a file named \"reflection_api_keys\"\n",
    "# exists in the same directory as this file.\n",
    "# This file contains the API keys for the models used in this flow.\n",
    "# It should be .gitignored and not shared publicly.\n",
    "# If this file is not present, you can either create it manually\n",
    "# or change the way API keys are loaded in the flow.\n",
    "\n",
    "\n",
    "def load_api_key_module(flow_name: str) -> ModuleType:\n",
    "    \"\"\"Load the api key module.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flow_name : str\n",
    "        The flow name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ModuleType\n",
    "        The api keys loading module.\n",
    "    \"\"\"\n",
    "    module_name = f\"{flow_name}_api_keys\"\n",
    "    if module_name in sys.modules:\n",
    "        return importlib.reload(sys.modules[module_name])\n",
    "    return importlib.import_module(module_name)\n",
    "\n",
    "\n",
    "__MODELS_MODULE__ = load_api_key_module(\"reflection\")\n",
    "\n",
    "\n",
    "def get_reflection_model_api_key(model_name: str) -> str:\n",
    "    \"\"\"Get the model api key.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        The model name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The model api key.\n",
    "    \"\"\"\n",
    "    return __MODELS_MODULE__.get_reflection_model_api_key(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc9b091",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e201d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_3_5_turbo_llm_config: dict[str, Any] = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"api_type\": \"openai\",\n",
    "    \"api_key\": get_reflection_model_api_key(\"gpt_3_5_turbo\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0bb384",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a37af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportUnnecessaryIsInstance=false\n",
    "\n",
    "critic = AssistantAgent(\n",
    "    name=\"critic\",\n",
    "    description=\"Critic\",\n",
    "    system_message=\"You are a critic. You review the work of the writer and provide constructive feedback to help improve the quality of the content.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_3_5_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "ethics_reviewer = AssistantAgent(\n",
    "    name=\"ethics_reviewer\",\n",
    "    description=\"Ethics Reviewer\",\n",
    "    system_message=\"You are an ethics reviewer, known for your ability to ensure that content is ethically sound and free from any potential ethical issues. Make sure your suggestion is concise (within 3 bullet points), concrete and to the point. Begin the review by stating your role.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_3_5_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "legal_reviewer = AssistantAgent(\n",
    "    name=\"legal_reviewer\",\n",
    "    description=\"Legal Reviewer\",\n",
    "    system_message=\"You are a legal reviewer, known for your ability to ensure that content is legally compliant and free from any potential legal issues. Make sure your suggestion is concise (within 3 bullet points), concrete and to the point. Begin the review by stating your role.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_3_5_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "meta_reviewer = AssistantAgent(\n",
    "    name=\"meta_reviewer\",\n",
    "    description=\"Meta Reviewer\",\n",
    "    system_message=\"You are a meta reviewer, you aggregate and review the work of other reviewers and give a final suggestion on the content.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_3_5_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "seo_reviewer = AssistantAgent(\n",
    "    name=\"seo_reviewer\",\n",
    "    description=\"SEO reviewer\",\n",
    "    system_message=\"You are an SEO reviewer, known for your ability to optimize content for search engines, ensuring that it ranks well and attracts organic traffic. Make sure your suggestion is concise (within 3 bullet points), concrete and to the point. Begin the review by stating your role.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_3_5_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "writer = AssistantAgent(\n",
    "    name=\"writer\",\n",
    "    description=\"Writer\",\n",
    "    system_message=\"You are a writer. You write engaging and concise blog posts (with title) on given topics. You must polish your writing based on the feedback you receive and give a refined version. Only return your final work without additional comments.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_3_5_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def nested_chat_message_writer_to_ethics_reviewer(\n",
    "    recipient: ConversableAgent,\n",
    "    messages: list[dict[str, Any]],\n",
    "    sender: ConversableAgent,\n",
    "    config: dict[str, Any],\n",
    ") -> Union[dict[str, Any], str]:\n",
    "    \"\"\"Ask for a review.\"\"\"\n",
    "    return f\"\"\"Review the following content.\n",
    "        \\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}\"\"\"\n",
    "\n",
    "\n",
    "def nested_chat_message_writer_to_legal_reviewer(\n",
    "    recipient: ConversableAgent,\n",
    "    messages: list[dict[str, Any]],\n",
    "    sender: ConversableAgent,\n",
    "    config: dict[str, Any],\n",
    ") -> Union[dict[str, Any], str]:\n",
    "    \"\"\"Ask for a review.\"\"\"\n",
    "    return f\"\"\"Review the following content.\n",
    "        \\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}\"\"\"\n",
    "\n",
    "\n",
    "def nested_chat_message_writer_to_seo_reviewer(\n",
    "    recipient: ConversableAgent,\n",
    "    messages: list[dict[str, Any]],\n",
    "    sender: ConversableAgent,\n",
    "    config: dict[str, Any],\n",
    ") -> Union[dict[str, Any], str]:\n",
    "    \"\"\"Ask for a review.\"\"\"\n",
    "    return f\"\"\"Review the following content.\n",
    "        \\n\\n {recipient.chat_messages_for_summary(sender)[-1]['content']}\"\"\"\n",
    "\n",
    "\n",
    "writer_chat_queue: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"summary_method\": \"last_msg\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\": True,\n",
    "        \"chat_id\": 0,\n",
    "        \"recipient\": seo_reviewer,\n",
    "        \"message\": nested_chat_message_writer_to_seo_reviewer,\n",
    "    },\n",
    "    {\n",
    "        \"summary_method\": \"last_msg\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\": True,\n",
    "        \"chat_id\": 1,\n",
    "        \"recipient\": legal_reviewer,\n",
    "        \"message\": nested_chat_message_writer_to_legal_reviewer,\n",
    "    },\n",
    "    {\n",
    "        \"summary_method\": \"last_msg\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\": True,\n",
    "        \"chat_id\": 2,\n",
    "        \"recipient\": ethics_reviewer,\n",
    "        \"message\": nested_chat_message_writer_to_ethics_reviewer,\n",
    "    },\n",
    "    {\n",
    "        \"summary_method\": \"last_msg\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\": True,\n",
    "        \"chat_id\": 3,\n",
    "        \"recipient\": meta_reviewer,\n",
    "        \"message\": \"Aggregate feedback from all reviewers and give final suggestions on the writing.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "writer.register_nested_chats(  # pyright: ignore\n",
    "    trigger=[\"critic\"],\n",
    "    chat_queue=writer_chat_queue,\n",
    "    use_async=False,\n",
    "    ignore_async_in_sync_chat=True,\n",
    ")\n",
    "\n",
    "\n",
    "def get_sqlite_out(dbname: str, table: str, csv_file: str) -> None:\n",
    "    \"\"\"Convert a sqlite table to csv and json files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dbname : str\n",
    "        The sqlite database name.\n",
    "    table : str\n",
    "        The table name.\n",
    "    csv_file : str\n",
    "        The csv file name.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(dbname)\n",
    "    query = f\"SELECT * FROM {table}\"  # nosec\n",
    "    try:\n",
    "        cursor = conn.execute(query)\n",
    "    except sqlite3.OperationalError:\n",
    "        conn.close()\n",
    "        return\n",
    "    rows = cursor.fetchall()\n",
    "    column_names = [description[0] for description in cursor.description]\n",
    "    data = [dict(zip(column_names, row)) for row in rows]\n",
    "    conn.close()\n",
    "    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        csv_writer = csv.DictWriter(file, fieldnames=column_names)\n",
    "        csv_writer.writeheader()\n",
    "        csv_writer.writerows(data)\n",
    "    json_file = csv_file.replace(\".csv\", \".json\")\n",
    "    with open(json_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def stop_logging() -> None:\n",
    "    \"\"\"Stop logging.\"\"\"\n",
    "    runtime_logging.stop()\n",
    "    if not os.path.exists(\"logs\"):\n",
    "        os.makedirs(\"logs\")\n",
    "    for table in [\n",
    "        \"chat_completions\",\n",
    "        \"agents\",\n",
    "        \"oai_wrappers\",\n",
    "        \"oai_clients\",\n",
    "        \"version\",\n",
    "        \"events\",\n",
    "        \"function_calls\",\n",
    "    ]:\n",
    "        dest = os.path.join(\"logs\", f\"{table}.csv\")\n",
    "        get_sqlite_out(\"flow.db\", table, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f507af07",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec477b2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main() -> Union[ChatResult, list[ChatResult], dict[int, ChatResult]]:\n",
    "    \"\"\"Start chatting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Union[ChatResult, list[ChatResult], dict[int, ChatResult]]\n",
    "        The result of the chat session, which can be a single ChatResult,\n",
    "        a list of ChatResults, or a dictionary mapping integers to ChatResults.\n",
    "    \"\"\"\n",
    "    results = critic.initiate_chat(\n",
    "        writer,\n",
    "        summary_method=\"last_msg\",\n",
    "        max_turns=2,\n",
    "        clear_history=True,\n",
    "        message=\"Write a concise but engaging blog post about DeepLearning.AI. Make sure the blog post is within 100 words.\",\n",
    "    )\n",
    "\n",
    "    stop_logging()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": false,
   "hide_notebook_metadata": true,
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
