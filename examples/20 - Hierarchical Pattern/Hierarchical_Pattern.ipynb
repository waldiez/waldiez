{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940515ef",
   "metadata": {},
   "source": [
    "# Name: Hierarchical_Pattern\n",
    "\n",
    "## Description: A waldiez flow for the AG2 example on hierarchical pattern: https://docs.ag2.ai/latest/docs/user-guide/advanced-concepts/pattern-cookbook/hierarchical/\n",
    "The Hierarchical, or Tree, Orchestration Pattern is a powerful approach to organizing multi-agent workflows, inspired by traditional organizational structures where work and information flow through a well-defined chain of command. This pattern creates a tree-structured arrangement of agents with clear levels of responsibility, specialization, and reporting relationships.\n",
    "\n",
    "## Tags: \n",
    "\n",
    "###ðŸ§© generated with â¤ï¸ by Waldiez.\n",
    "\n",
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bec964",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# # !{sys.executable} -m pip install -q ag2[openai]==0.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5376c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f0ce7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import csv\n",
    "import importlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "import sys\n",
    "import threading\n",
    "import traceback\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from types import ModuleType\n",
    "from typing import (\n",
    "    Annotated,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Coroutine,\n",
    "    Dict,\n",
    "    List,\n",
    "    Optional,\n",
    "    Set,\n",
    "    Tuple,\n",
    "    TypedDict,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "import autogen  # type: ignore\n",
    "from autogen import (\n",
    "    Agent,\n",
    "    Cache,\n",
    "    ChatResult,\n",
    "    ConversableAgent,\n",
    "    GroupChat,\n",
    "    UserProxyAgent,\n",
    "    register_function,\n",
    "    runtime_logging,\n",
    ")\n",
    "from autogen.agentchat import GroupChatManager, run_group_chat\n",
    "from autogen.agentchat.group import (\n",
    "    AgentNameTarget,\n",
    "    AgentTarget,\n",
    "    ContextExpression,\n",
    "    ContextVariables,\n",
    "    ExpressionAvailableCondition,\n",
    "    ExpressionContextCondition,\n",
    "    OnCondition,\n",
    "    OnContextCondition,\n",
    "    ReplyResult,\n",
    "    RevertToUserTarget,\n",
    "    StringLLMCondition,\n",
    "    TerminateTarget,\n",
    ")\n",
    "from autogen.agentchat.group.patterns import DefaultPattern\n",
    "from autogen.agentchat.group.patterns.pattern import Pattern\n",
    "from autogen.events import BaseEvent\n",
    "from autogen.io.run_response import AsyncRunResponseProtocol, RunResponseProtocol\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Common environment variable setup for Waldiez flows\n",
    "load_dotenv(override=True)\n",
    "os.environ[\"AUTOGEN_USE_DOCKER\"] = \"0\"\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"False\"\n",
    "#\n",
    "# let's try to avoid:\n",
    "# module 'numpy' has no attribute '_no_nep50_warning'\"\n",
    "# ref: https://github.com/numpy/numpy/blob/v2.2.2/doc/source/release/2.2.0-notes.rst#nep-50-promotion-state-option-removed\n",
    "os.environ[\"NEP50_DEPRECATION_WARNING\"] = \"0\"\n",
    "os.environ[\"NEP50_DISABLE_WARNING\"] = \"1\"\n",
    "os.environ[\"NPY_PROMOTION_STATE\"] = \"weak\"\n",
    "if not hasattr(np, \"_no_pep50_warning\"):\n",
    "\n",
    "    import contextlib\n",
    "    from typing import Generator\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _np_no_nep50_warning() -> Generator[None, None, None]:\n",
    "        \"\"\"Dummy function to avoid the warning.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        None\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "        yield\n",
    "\n",
    "    setattr(np, \"_no_pep50_warning\", _np_no_nep50_warning)  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4848fc37",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b95716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_logging() -> None:\n",
    "    \"\"\"Start logging.\"\"\"\n",
    "    runtime_logging.start(\n",
    "        logger_type=\"sqlite\",\n",
    "        config={\"dbname\": \"flow.db\"},\n",
    "    )\n",
    "\n",
    "\n",
    "start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d132e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Load model API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284bb7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# This section assumes that a file named:\n",
    "# \"hierarchical_pattern_api_keys.py\"\n",
    "# exists in the same directory as this file.\n",
    "# This file contains the API keys for the models used in this flow.\n",
    "# It should be .gitignored and not shared publicly.\n",
    "# If this file is not present, you can either create it manually\n",
    "# or change the way API keys are loaded in the flow.\n",
    "\n",
    "\n",
    "def load_api_key_module(flow_name: str) -> ModuleType:\n",
    "    \"\"\"Load the api key module.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flow_name : str\n",
    "        The flow name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ModuleType\n",
    "        The api keys loading module.\n",
    "    \"\"\"\n",
    "    module_name = f\"{flow_name}_api_keys\"\n",
    "    if module_name in sys.modules:\n",
    "        return importlib.reload(sys.modules[module_name])\n",
    "    return importlib.import_module(module_name)\n",
    "\n",
    "\n",
    "__MODELS_MODULE__ = load_api_key_module(\"hierarchical_pattern\")\n",
    "\n",
    "\n",
    "def get_hierarchical_pattern_model_api_key(model_name: str) -> str:\n",
    "    \"\"\"Get the model api key.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        The model name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The model api key.\n",
    "    \"\"\"\n",
    "    return __MODELS_MODULE__.get_hierarchical_pattern_model_api_key(model_name)\n",
    "\n",
    "\n",
    "class GroupDict(TypedDict):\n",
    "    \"\"\"Group related global dict.\"\"\"\n",
    "\n",
    "    chats: dict[str, GroupChat]\n",
    "    patterns: dict[str, Pattern]\n",
    "\n",
    "\n",
    "__GROUP__: GroupDict = {\"chats\": {}, \"patterns\": {}}\n",
    "\n",
    "__AGENTS__: dict[str, ConversableAgent] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22246f6d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40237af",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def complete_solar_research(\n",
    "    research_content: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Submit solar energy research findings\"\"\"\n",
    "    context_variables[\"solar_research\"] = research_content\n",
    "    context_variables[\"specialist_a1_completed\"] = True\n",
    "\n",
    "    # Check if both specialists under Manager A have completed their tasks\n",
    "    if (\n",
    "        context_variables[\"specialist_a1_completed\"]\n",
    "        and context_variables[\"specialist_a2_completed\"]\n",
    "    ):\n",
    "        context_variables[\"manager_a_completed\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"Solar research completed and stored.\",\n",
    "        context_variables=context_variables,\n",
    "        target=AgentTarget(renewable_manager),\n",
    "    )\n",
    "\n",
    "\n",
    "def complete_wind_research(\n",
    "    research_content: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Submit wind energy research findings\"\"\"\n",
    "    context_variables[\"wind_research\"] = research_content\n",
    "    context_variables[\"specialist_a2_completed\"] = True\n",
    "\n",
    "    # Check if both specialists under Manager A have completed their tasks\n",
    "    if (\n",
    "        context_variables[\"specialist_a1_completed\"]\n",
    "        and context_variables[\"specialist_a2_completed\"]\n",
    "    ):\n",
    "        context_variables[\"manager_a_completed\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"Wind research completed and stored.\",\n",
    "        context_variables=context_variables,\n",
    "        target=AgentTarget(renewable_manager),\n",
    "    )\n",
    "\n",
    "\n",
    "def complete_hydro_research(\n",
    "    research_content: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Submit hydroelectric energy research findings\"\"\"\n",
    "    context_variables[\"hydro_research\"] = research_content\n",
    "    context_variables[\"specialist_b1_completed\"] = True\n",
    "\n",
    "    # Check if both specialists under Manager B have completed their tasks\n",
    "    if (\n",
    "        context_variables[\"specialist_b1_completed\"]\n",
    "        and context_variables[\"specialist_b2_completed\"]\n",
    "    ):\n",
    "        context_variables[\"manager_b_completed\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"Hydroelectric research completed and stored.\",\n",
    "        context_variables=context_variables,\n",
    "        target=AgentTarget(storage_manager),\n",
    "    )\n",
    "\n",
    "\n",
    "def complete_geothermal_research(\n",
    "    research_content: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Submit geothermal energy research findings\"\"\"\n",
    "    context_variables[\"geothermal_research\"] = research_content\n",
    "    context_variables[\"specialist_b2_completed\"] = True\n",
    "\n",
    "    # Check if both specialists under Manager B have completed their tasks\n",
    "    if (\n",
    "        context_variables[\"specialist_b1_completed\"]\n",
    "        and context_variables[\"specialist_b2_completed\"]\n",
    "    ):\n",
    "        context_variables[\"manager_b_completed\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"Geothermal research completed and stored.\",\n",
    "        context_variables=context_variables,\n",
    "        target=AgentTarget(storage_manager),\n",
    "    )\n",
    "\n",
    "\n",
    "def complete_biofuel_research(\n",
    "    research_content: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Submit biofuel research findings\"\"\"\n",
    "    context_variables[\"biofuel_research\"] = research_content\n",
    "    context_variables[\"specialist_c1_completed\"] = True\n",
    "    context_variables[\"manager_c_completed\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"Biofuel research completed and stored.\",\n",
    "        context_variables=context_variables,\n",
    "        target=AgentTarget(alternative_manager),\n",
    "    )\n",
    "\n",
    "\n",
    "def compile_renewable_section(\n",
    "    section_content: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Compile the renewable energy section (solar and wind) for the final report\"\"\"\n",
    "    context_variables[\"report_sections\"][\"renewable\"] = section_content\n",
    "\n",
    "    # Check if all managers have submitted their sections\n",
    "    if all(\n",
    "        key in context_variables[\"report_sections\"]\n",
    "        for key in [\"renewable\", \"storage\", \"alternative\"]\n",
    "    ):\n",
    "        context_variables[\"executive_review_ready\"] = True\n",
    "        return ReplyResult(\n",
    "            message=\"Renewable energy section compiled. All sections are now ready for executive review.\",\n",
    "            context_variables=context_variables,\n",
    "            target=AgentTarget(executive_agent),\n",
    "        )\n",
    "    else:\n",
    "        return ReplyResult(\n",
    "            message=\"Renewable energy section compiled and stored.\",\n",
    "            context_variables=context_variables,\n",
    "            target=AgentTarget(executive_agent),\n",
    "        )\n",
    "\n",
    "\n",
    "def compile_storage_section(\n",
    "    section_content: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Compile the energy storage section (hydro and geothermal) for the final report\"\"\"\n",
    "    context_variables[\"report_sections\"][\"storage\"] = section_content\n",
    "\n",
    "    # Check if all managers have submitted their sections\n",
    "    if all(\n",
    "        key in context_variables[\"report_sections\"]\n",
    "        for key in [\"renewable\", \"storage\", \"alternative\"]\n",
    "    ):\n",
    "        context_variables[\"executive_review_ready\"] = True\n",
    "        return ReplyResult(\n",
    "            message=\"Energy storage section compiled. All sections are now ready for executive review.\",\n",
    "            context_variables=context_variables,\n",
    "            target=AgentTarget(executive_agent),\n",
    "        )\n",
    "    else:\n",
    "        return ReplyResult(\n",
    "            message=\"Energy storage section compiled and stored.\",\n",
    "            context_variables=context_variables,\n",
    "            target=AgentTarget(executive_agent),\n",
    "        )\n",
    "\n",
    "\n",
    "def compile_alternative_section(\n",
    "    section_content: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Compile the alternative energy section (biofuels) for the final report\"\"\"\n",
    "    context_variables[\"report_sections\"][\"alternative\"] = section_content\n",
    "\n",
    "    # Check if all managers have submitted their sections\n",
    "    if all(\n",
    "        key in context_variables[\"report_sections\"]\n",
    "        for key in [\"renewable\", \"storage\", \"alternative\"]\n",
    "    ):\n",
    "        context_variables[\"executive_review_ready\"] = True\n",
    "        return ReplyResult(\n",
    "            message=\"Alternative energy section compiled. All sections are now ready for executive review.\",\n",
    "            context_variables=context_variables,\n",
    "            target=AgentTarget(executive_agent),\n",
    "        )\n",
    "    else:\n",
    "        return ReplyResult(\n",
    "            message=\"Alternative energy section compiled and stored.\",\n",
    "            context_variables=context_variables,\n",
    "            target=AgentTarget(executive_agent),\n",
    "        )\n",
    "\n",
    "\n",
    "def initiate_research(context_variables: ContextVariables) -> ReplyResult:\n",
    "    \"\"\"Initiate the research process by delegating to managers\"\"\"\n",
    "    context_variables[\"task_started\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"Research initiated. Tasks have been delegated to the renewable energy manager, storage manager, and alternative energy manager.\",\n",
    "        context_variables=context_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "def compile_final_report(\n",
    "    report_content: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Compile the final comprehensive report from all sections\"\"\"\n",
    "    context_variables[\"final_report\"] = report_content\n",
    "    context_variables[\"task_completed\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"Final report compiled successfully. The comprehensive renewable energy report is now complete.\",\n",
    "        context_variables=context_variables,\n",
    "        target=AgentTarget(user),  # Return to user with final report\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f5bc6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ce586",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4o_mini_llm_config: dict[str, Any] = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"api_type\": \"openai\",\n",
    "    \"api_key\": get_hierarchical_pattern_model_api_key(\"gpt_4o_mini\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307391c8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73db764",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_manager = ConversableAgent(\n",
    "    name=\"alternative_manager\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are the manager for alternative energy solutions, overseeing biofuel research.\\n        Your responsibilities include:\\n        1. Reviewing the research from your specialist\\n        2. Ensuring the information is accurate and comprehensive\\n        3. Synthesizing the information into a cohesive section on alternative energy solutions\\n        4. Submitting the compiled research to the executive for final report creation\\n\\n        Use your tools only one at a time.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        compile_alternative_section,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4o_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"alternative_manager\"] = alternative_manager\n",
    "\n",
    "biofuel_specialist = ConversableAgent(\n",
    "    name=\"biofuel_specialist\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are a specialist in biofuel technologies.\\n        Your task is to research and provide concise information about:\\n        1. Current state of biofuel technology\\n        2. Types of biofuels and their applications\\n        3. Cost comparison with fossil fuels\\n        4. Major companies and countries leading in biofuel production\\n\\n        Be thorough but concise. Your research will be used as part of a larger report.\\n\\n        Use your tools only one at a time.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        complete_biofuel_research,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4o_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"biofuel_specialist\"] = biofuel_specialist\n",
    "\n",
    "executive_agent = ConversableAgent(\n",
    "    name=\"executive_agent\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are the executive overseeing the creation of a comprehensive report on renewable energy technologies.\\n\\n        You have exactly three manager agents reporting to you, each responsible for specific technology domains:\\n        1. Renewable Manager - Oversees solar and wind energy research\\n        2. Storage Manager - Oversees hydroelectric and geothermal energy research\\n        3. Alternative Manager - Oversees biofuel research\\n\\n        Your responsibilities include:\\n        1. Delegating research tasks to these three specific manager agents\\n        2. Providing overall direction and ensuring alignment with the project goals\\n        3. Reviewing the compiled sections from each manager\\n        4. Synthesizing all sections into a cohesive final report with executive summary\\n        5. Ensuring the report is comprehensive, balanced, and meets high-quality standards\\n\\n        Do not create or attempt to delegate to managers that don't exist in this structure.\\n\\n        The final report should include:\\n        - Executive Summary\\n        - Introduction to Renewable Energy\\n        - Three main sections:\\n        * Solar and Wind Energy (from Renewable Manager)\\n        * Hydroelectric and Geothermal Energy (from Storage Manager)\\n        * Biofuel Technologies (from Alternative Manager)\\n        - Comparison of technologies\\n        - Future outlook and recommendations\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        initiate_research,\n",
    "        compile_final_report,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4o_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"executive_agent\"] = executive_agent\n",
    "\n",
    "geothermal_specialist = ConversableAgent(\n",
    "    name=\"geothermal_specialist\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are a specialist in geothermal energy technologies.\\n        Your task is to research and provide concise information about:\\n        1. Current state of geothermal technology\\n        2. Types of geothermal systems and efficiency rates\\n        3. Cost comparison with fossil fuels\\n        4. Major companies and countries leading in geothermal energy\\n\\n        Be thorough but concise. Your research will be used as part of a larger report.\\n\\n        Use your tools only one at a time.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        complete_geothermal_research,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4o_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"geothermal_specialist\"] = geothermal_specialist\n",
    "\n",
    "hydro_specialist = ConversableAgent(\n",
    "    name=\"hydro_specialist\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are a specialist in hydroelectric energy technologies.\\n        Your task is to research and provide concise information about:\\n        1. Current state of hydroelectric technology\\n        2. Types of hydroelectric generation (dams, run-of-river, pumped storage)\\n        3. Cost comparison with fossil fuels\\n        4. Major companies and countries leading in hydroelectric energy\\n\\n        Be thorough but concise. Your research will be used as part of a larger report.\\n\\n        Use your tools only one at a time.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        complete_hydro_research,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4o_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"hydro_specialist\"] = hydro_specialist\n",
    "\n",
    "renewable_manager = ConversableAgent(\n",
    "    name=\"renewable_manager\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are the manager for renewable energy research, specifically overseeing solar and wind energy specialists.\\n        Your responsibilities include:\\n        1. Reviewing the research from your specialists\\n        2. Ensuring the information is accurate and comprehensive\\n        3. Synthesizing the information into a cohesive section on renewable energy\\n        4. Submitting the compiled research to the executive for final report creation\\n\\n        You should wait until both specialists have completed their research before compiling your section.\\n\\n        Use your tools only one at a time.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        compile_renewable_section,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4o_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"renewable_manager\"] = renewable_manager\n",
    "\n",
    "solar_specialist = ConversableAgent(\n",
    "    name=\"solar_specialist\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are a specialist in solar energy technologies.\\n        Your task is to research and provide concise information about:\\n        1. Current state of solar technology\\n        2. Efficiency rates of different types of solar panels\\n        3. Cost comparison with fossil fuels\\n        4. Major companies and countries leading in solar energy\\n\\n        Be thorough but concise. Your research will be used as part of a larger report.\\n\\n        Use your tools only one at a time.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        complete_solar_research,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4o_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"solar_specialist\"] = solar_specialist\n",
    "\n",
    "storage_manager = ConversableAgent(\n",
    "    name=\"storage_manager\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are the manager for energy storage and hydroelectric technologies, overseeing hydroelectric and geothermal energy specialists.\\n        Your responsibilities include:\\n        1. Reviewing the research from your specialists\\n        2. Ensuring the information is accurate and comprehensive\\n        3. Synthesizing the information into a cohesive section on energy storage and hydroelectric solutions\\n        4. Submitting the compiled research to the executive for final report creation\\n\\n        You should wait until both specialists have completed their research before compiling your section.\\n\\n        Use your tools only one at a time.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        compile_storage_section,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4o_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"storage_manager\"] = storage_manager\n",
    "\n",
    "user = UserProxyAgent(\n",
    "    name=\"user\",\n",
    "    description=\"A new User agent\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    llm_config=False,\n",
    ")\n",
    "\n",
    "__AGENTS__[\"user\"] = user\n",
    "\n",
    "wind_specialist = ConversableAgent(\n",
    "    name=\"wind_specialist\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are a specialist in wind energy technologies.\\n        Your task is to research and provide concise information about:\\n        1. Current state of wind technology (onshore/offshore)\\n        2. Efficiency rates of modern wind turbines\\n        3. Cost comparison with fossil fuels\\n        4. Major companies and countries leading in wind energy\\n\\n        Be thorough but concise. Your research will be used as part of a larger report.\\n\\n        Use your tools only one at a time.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        complete_wind_research,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4o_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"wind_specialist\"] = wind_specialist\n",
    "\n",
    "alternative_manager.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(biofuel_specialist),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"not(${specialist_c1_completed})\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${task_started} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "alternative_manager.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=AgentTarget(executive_agent),\n",
    "        condition=StringLLMCondition(\n",
    "            prompt=\"Return to the executive with the compiled alternative energy section\"\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${manager_c_completed} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "biofuel_specialist.handoffs.set_after_work(target=AgentTarget(alternative_manager))\n",
    "\n",
    "executive_agent.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(renewable_manager),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"not(${manager_a_completed})\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${task_started} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "executive_agent.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(storage_manager),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"not(${manager_b_completed})\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${task_started} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "executive_agent.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(alternative_manager),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"not(${manager_c_completed})\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${task_started} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "executive_agent.handoffs.set_after_work(target=RevertToUserTarget())\n",
    "\n",
    "geothermal_specialist.handoffs.set_after_work(target=AgentTarget(renewable_manager))\n",
    "\n",
    "hydro_specialist.handoffs.set_after_work(target=AgentTarget(storage_manager))\n",
    "\n",
    "renewable_manager.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(solar_specialist),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"not(${specialist_a1_completed})\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${task_started} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "renewable_manager.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(wind_specialist),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"not(${specialist_a2_completed})\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${task_started} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "renewable_manager.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=AgentTarget(executive_agent),\n",
    "        condition=StringLLMCondition(\n",
    "            prompt=\"Return to the executive after your report has been compiled.\"\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${manager_a_completed} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "renewable_manager.handoffs.set_after_work(target=AgentTarget(executive_agent))\n",
    "\n",
    "solar_specialist.handoffs.set_after_work(target=AgentTarget(renewable_manager))\n",
    "\n",
    "storage_manager.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(hydro_specialist),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"not(${specialist_b1_completed})\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${task_started} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "storage_manager.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(geothermal_specialist),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"not(${specialist_b2_completed})\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${task_started} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "storage_manager.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=AgentTarget(executive_agent),\n",
    "        condition=StringLLMCondition(\n",
    "            prompt=\"Return to the executive after your report has been compiled.\"\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"${manager_b_completed} == True\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "storage_manager.handoffs.set_after_work(target=AgentTarget(executive_agent))\n",
    "\n",
    "wind_specialist.handoffs.set_after_work(target=AgentTarget(renewable_manager))\n",
    "\n",
    "__INITIAL_MSG__ = \"We need a comprehensive report on the current state of renewable energy technologies. Please coordinate the research and compilation of this report.\"\n",
    "\n",
    "_pattern = DefaultPattern(\n",
    "    initial_agent=executive_agent,\n",
    "    agents=[\n",
    "        solar_specialist,\n",
    "        wind_specialist,\n",
    "        hydro_specialist,\n",
    "        geothermal_specialist,\n",
    "        biofuel_specialist,\n",
    "        renewable_manager,\n",
    "        storage_manager,\n",
    "        alternative_manager,\n",
    "        executive_agent,\n",
    "    ],\n",
    "    user_agent=user,\n",
    "    group_manager_args={\n",
    "        \"llm_config\": False,\n",
    "        \"name\": \"\",\n",
    "    },\n",
    "    context_variables=ContextVariables(\n",
    "        data={\n",
    "            \"task_started\": False,\n",
    "            \"task_completed\": False,\n",
    "            \"executive_review_ready\": False,\n",
    "            \"manager_a_completed\": False,\n",
    "            \"manager_b_completed\": False,\n",
    "            \"manager_c_completed\": False,\n",
    "            \"specialist_a1_completed\": False,\n",
    "            \"specialist_a2_completed\": False,\n",
    "            \"specialist_b1_completed\": False,\n",
    "            \"specialist_c1_completed\": False,\n",
    "            \"specialist_b2_completed\": False,\n",
    "            \"solar_research\": \"\",\n",
    "            \"wind_research\": \"\",\n",
    "            \"hydro_research\": \"\",\n",
    "            \"geothermal_research\": \"\",\n",
    "            \"biofuel_research\": \"\",\n",
    "            \"report_sections\": {},\n",
    "            \"final_report\": \"\",\n",
    "        }\n",
    "    ),\n",
    "    group_after_work=TerminateTarget(),\n",
    ")\n",
    "\n",
    "__GROUP__[\"patterns\"][\"_pattern\"] = _pattern\n",
    "\n",
    "\n",
    "def get_sqlite_out(dbname: str, table: str, csv_file: str) -> None:\n",
    "    \"\"\"Convert a sqlite table to csv and json files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dbname : str\n",
    "        The sqlite database name.\n",
    "    table : str\n",
    "        The table name.\n",
    "    csv_file : str\n",
    "        The csv file name.\n",
    "    \"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements\n",
    "    try:\n",
    "        conn = sqlite3.connect(dbname)\n",
    "    except BaseException:\n",
    "        return\n",
    "    query = f\"SELECT * FROM {table}\"  # nosec\n",
    "    try:\n",
    "        cursor = conn.execute(query)\n",
    "    except BaseException:\n",
    "        conn.close()\n",
    "        return\n",
    "    try:\n",
    "        rows = cursor.fetchall()\n",
    "        column_names = [description[0] for description in cursor.description]\n",
    "        data = [dict(zip(column_names, row, strict=True)) for row in rows]\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    except BaseException:\n",
    "        try:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "        except BaseException:\n",
    "            pass\n",
    "        return\n",
    "    try:\n",
    "        with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            csv_writer = csv.DictWriter(file, fieldnames=column_names)\n",
    "            csv_writer.writeheader()\n",
    "            csv_writer.writerows(data)\n",
    "        json_file = csv_file.replace(\".csv\", \".json\")\n",
    "        with open(json_file, \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "            json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "    except BaseException:\n",
    "        return\n",
    "\n",
    "\n",
    "def stop_logging() -> None:\n",
    "    \"\"\"Stop logging.\"\"\"\n",
    "    runtime_logging.stop()\n",
    "    if not os.path.exists(\"logs\"):\n",
    "        os.makedirs(\"logs\")\n",
    "    for table in [\n",
    "        \"chat_completions\",\n",
    "        \"agents\",\n",
    "        \"oai_wrappers\",\n",
    "        \"oai_clients\",\n",
    "        \"version\",\n",
    "        \"events\",\n",
    "        \"function_calls\",\n",
    "    ]:\n",
    "        dest = os.path.join(\"logs\", f\"{table}.csv\")\n",
    "        get_sqlite_out(\"flow.db\", table, dest)\n",
    "\n",
    "\n",
    "def _check_for_extra_agents(agent: ConversableAgent) -> list[ConversableAgent]:\n",
    "    _extra_agents: list[ConversableAgent] = []\n",
    "    _agent_cls_name = agent.__class__.__name__\n",
    "    if _agent_cls_name == \"CaptainAgent\":\n",
    "        _assistant_agent = getattr(agent, \"assistant\", None)\n",
    "        if _assistant_agent and _assistant_agent not in _extra_agents:\n",
    "            _extra_agents.append(_assistant_agent)\n",
    "        _executor_agent = getattr(agent, \"executor\", None)\n",
    "        if _executor_agent and _executor_agent not in _extra_agents:\n",
    "            _extra_agents.append(_executor_agent)\n",
    "    return _extra_agents\n",
    "\n",
    "\n",
    "def _check_for_group_members(agent: ConversableAgent) -> list[ConversableAgent]:\n",
    "    _extra_agents: list[ConversableAgent] = []\n",
    "    _group_chat = getattr(agent, \"_groupchat\", None)\n",
    "    if _group_chat:\n",
    "        _chat_agents = getattr(_group_chat, \"agents\", [])\n",
    "        if isinstance(_chat_agents, list):\n",
    "            for _group_member in _chat_agents:\n",
    "                if _group_member not in _extra_agents:\n",
    "                    _extra_agents.append(_group_member)\n",
    "    _manager = getattr(agent, \"_group_manager\", None)\n",
    "    if _manager:\n",
    "        if _manager not in _extra_agents:\n",
    "            _extra_agents.append(_manager)\n",
    "        for _group_member in _check_for_group_members(_manager):\n",
    "            if _group_member not in _extra_agents:\n",
    "                _extra_agents.append(_group_member)\n",
    "    return _extra_agents\n",
    "\n",
    "\n",
    "def _get_known_agents() -> list[ConversableAgent]:\n",
    "    _known_agents: list[ConversableAgent] = []\n",
    "    if user not in _known_agents:\n",
    "        _known_agents.append(user)\n",
    "    _known_agents.append(user)\n",
    "    for _group_member in _check_for_group_members(user):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(user):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if solar_specialist not in _known_agents:\n",
    "        _known_agents.append(solar_specialist)\n",
    "    _known_agents.append(solar_specialist)\n",
    "    for _group_member in _check_for_group_members(solar_specialist):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(solar_specialist):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if wind_specialist not in _known_agents:\n",
    "        _known_agents.append(wind_specialist)\n",
    "    _known_agents.append(wind_specialist)\n",
    "    for _group_member in _check_for_group_members(wind_specialist):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(wind_specialist):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if hydro_specialist not in _known_agents:\n",
    "        _known_agents.append(hydro_specialist)\n",
    "    _known_agents.append(hydro_specialist)\n",
    "    for _group_member in _check_for_group_members(hydro_specialist):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(hydro_specialist):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if geothermal_specialist not in _known_agents:\n",
    "        _known_agents.append(geothermal_specialist)\n",
    "    _known_agents.append(geothermal_specialist)\n",
    "    for _group_member in _check_for_group_members(geothermal_specialist):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(geothermal_specialist):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if biofuel_specialist not in _known_agents:\n",
    "        _known_agents.append(biofuel_specialist)\n",
    "    _known_agents.append(biofuel_specialist)\n",
    "    for _group_member in _check_for_group_members(biofuel_specialist):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(biofuel_specialist):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if renewable_manager not in _known_agents:\n",
    "        _known_agents.append(renewable_manager)\n",
    "    _known_agents.append(renewable_manager)\n",
    "    for _group_member in _check_for_group_members(renewable_manager):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(renewable_manager):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if storage_manager not in _known_agents:\n",
    "        _known_agents.append(storage_manager)\n",
    "    _known_agents.append(storage_manager)\n",
    "    for _group_member in _check_for_group_members(storage_manager):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(storage_manager):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if alternative_manager not in _known_agents:\n",
    "        _known_agents.append(alternative_manager)\n",
    "    _known_agents.append(alternative_manager)\n",
    "    for _group_member in _check_for_group_members(alternative_manager):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(alternative_manager):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if executive_agent not in _known_agents:\n",
    "        _known_agents.append(executive_agent)\n",
    "    _known_agents.append(executive_agent)\n",
    "    for _group_member in _check_for_group_members(executive_agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(executive_agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "    return _known_agents\n",
    "\n",
    "\n",
    "def store_error(exc: BaseException | None = None) -> None:\n",
    "    \"\"\"Store the error in error.json.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exc : BaseException | None\n",
    "        The exception we got if any.\n",
    "    \"\"\"\n",
    "    reason = \"Event handler stopped processing\" if not exc else traceback.format_exc()\n",
    "    try:\n",
    "        with open(\"error.json\", \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "            file.write(json.dumps({\"error\": reason}))\n",
    "    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "        pass\n",
    "\n",
    "\n",
    "def store_results(result_dicts: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Store the results to results.json.\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_dicts : list[dict[str, Any]]\n",
    "        The list of the results.\n",
    "    \"\"\"\n",
    "    with open(\"results.json\", \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "        file.write(json.dumps({\"results\": result_dicts}, indent=4, ensure_ascii=False))\n",
    "\n",
    "\n",
    "def _get_agent_by_name(\n",
    "    agents: list[ConversableAgent], agent_name: str\n",
    ") -> tuple[int, ConversableAgent | None]:\n",
    "    \"\"\"Get an agent by its name.\"\"\"\n",
    "    for ind, agent in enumerate(agents):\n",
    "        if agent.name == agent_name:\n",
    "            return ind, agent\n",
    "    return -1, None\n",
    "\n",
    "\n",
    "def _handle_resume_group_pattern(\n",
    "    detected_pattern: Pattern, state_messages: list[dict[str, Any]]\n",
    ") -> None:\n",
    "    \"\"\"Handle detected pattern for resuming a group chat.\"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements\n",
    "    try:\n",
    "        _pattern_type = getattr(detected_pattern.__class__, \"__name__\", None)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if _pattern_type == \"RoundRobinPattern\" and state_messages:\n",
    "        last_message = state_messages[-1]\n",
    "        if not last_message or not isinstance(last_message, dict):\n",
    "            return\n",
    "        last_agent_name = last_message.get(\"name\", \"\")\n",
    "        if not last_agent_name:\n",
    "            return\n",
    "        try:\n",
    "            idx, last_agent = _get_agent_by_name(\n",
    "                detected_pattern.agents, last_agent_name\n",
    "            )\n",
    "            if last_agent and len(detected_pattern.agents) >= (idx + 1):\n",
    "                detected_pattern.agents.append(detected_pattern.user_agent)\n",
    "                detected_pattern.initial_agent = detected_pattern.agents[idx + 1]\n",
    "                detected_pattern.user_agent = detected_pattern.agents[idx]\n",
    "                # fmt: off\n",
    "                new_agent_order_list = detected_pattern.agents[idx+1:] + detected_pattern.agents[:idx]\n",
    "                # fmt: on\n",
    "                detected_pattern.agents = new_agent_order_list\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "\n",
    "def _prepare_resume(state_json: str | Path | None = None) -> None:\n",
    "    \"\"\"Prepare resuming a chat from state.json.\n",
    "\n",
    "    state.json format:\n",
    "        {\n",
    "            \"messages\": [{\"content\": \"..\", \"role\": \"...\", \"name\": \"...\"}],\n",
    "            \"context_variables\": {\"key1\": \"value1\", \"key2\": 4, \"key3\": [], \"key4\": {\"other\": \"key\"}}\n",
    "        }\n",
    "    metadata.json format:\n",
    "        {\n",
    "            \"type\": \"group\",\n",
    "            \"group\": {  # one of:\n",
    "                \"pattern\" : \"<pattern_name>\",\n",
    "                \"manager\" : \"<manager_name>\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state_json : str | Path | None\n",
    "        The path to state.json to load previous state.\n",
    "    \"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements,global-statement\n",
    "    global __INITIAL_MSG__\n",
    "    if not state_json or not Path(state_json).is_file():\n",
    "        return\n",
    "    metadata_json = str(state_json).replace(\"state.json\", \"metadata.json\")\n",
    "    if not metadata_json or not Path(metadata_json).is_file():\n",
    "        return\n",
    "    try:\n",
    "        with open(metadata_json, \"r\", encoding=\"utf-8\") as f:\n",
    "            _metadata_dict = json.load(f)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if not _metadata_dict or not isinstance(_metadata_dict, dict):\n",
    "        return\n",
    "    _state_chat_type = _metadata_dict.get(\"type\", \"\")\n",
    "    if _state_chat_type != \"group\":\n",
    "        # only resume group chats\n",
    "        return\n",
    "    _state_group_details = _metadata_dict.get(\"group\", {})\n",
    "    if not _state_group_details or not isinstance(_state_group_details, dict):\n",
    "        return\n",
    "    # either pattern or manager\n",
    "    _state_group_pattern = _state_group_details.get(\"pattern\", \"\")\n",
    "    _state_group_manager = _state_group_details.get(\"manager\", \"\")\n",
    "    if not _state_group_pattern and not _state_group_manager:\n",
    "        return\n",
    "    try:\n",
    "        with open(state_json, \"r\", encoding=\"utf-8\") as f:\n",
    "            _state_dict = json.load(f)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if not _state_dict or not isinstance(_state_dict, dict):\n",
    "        return\n",
    "    _state_messages = _state_dict.get(\"messages\", [])\n",
    "    _detected_pattern = None\n",
    "    if _state_group_pattern and isinstance(_state_group_pattern, str):\n",
    "        _detected_pattern = __GROUP__[\"patterns\"].get(_state_group_pattern, None)\n",
    "        if _detected_pattern:\n",
    "            _state_context_variables = _state_dict.get(\"context_variables\", {})\n",
    "            if _state_context_variables and isinstance(_state_context_variables, dict):\n",
    "                _detected_pattern.context_variables = ContextVariables(\n",
    "                    data=_state_context_variables\n",
    "                )\n",
    "        if _state_messages and isinstance(_state_messages, list):\n",
    "            __INITIAL_MSG__ = _state_messages\n",
    "    elif _state_group_manager and isinstance(_state_group_manager, str):\n",
    "        _known_group_manager = __AGENTS__.get(_state_group_manager, None)\n",
    "        if _known_group_manager and hasattr(_known_group_manager, \"groupchat\"):\n",
    "            if _state_messages and isinstance(_state_messages, list):\n",
    "                _known_group_manager.groupchat.messages = _state_messages\n",
    "        else:\n",
    "            _detected_pattern = __GROUP__[\"patterns\"].get(\n",
    "                f\"{_state_group_manager}_pattern\"\n",
    "            )\n",
    "            if _detected_pattern:\n",
    "                _state_context_variables = _state_dict.get(\"context_variables\", {})\n",
    "                if _state_context_variables and isinstance(\n",
    "                    _state_context_variables, dict\n",
    "                ):\n",
    "                    _detected_pattern.context_variables = ContextVariables(\n",
    "                        data=_state_context_variables\n",
    "                    )\n",
    "            if _state_messages and isinstance(_state_messages, list):\n",
    "                __INITIAL_MSG__ = _state_messages\n",
    "    if _detected_pattern and _state_messages and isinstance(_state_messages, list):\n",
    "        _handle_resume_group_pattern(_detected_pattern, _state_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d12ce0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7766a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main(\n",
    "    on_event: Callable[[BaseEvent, list[ConversableAgent]], bool] | None = None,\n",
    "    state_json: str | Path | None = None,\n",
    ") -> list[dict[str, Any]]:\n",
    "    \"\"\"Start chatting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict[str, Any]]\n",
    "        The result of the chat session.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    SystemExit\n",
    "        If the user interrupts the chat session.\n",
    "    \"\"\"\n",
    "    if state_json:\n",
    "        _prepare_resume(state_json)\n",
    "    results: list[RunResponseProtocol] | RunResponseProtocol = []\n",
    "    result_dicts: list[dict[str, Any]] = []\n",
    "    a_pause_event = asyncio.Event()\n",
    "    a_pause_event.set()\n",
    "    pause_event = threading.Event()\n",
    "    pause_event.set()\n",
    "    with Cache.disk(cache_seed=42) as cache:\n",
    "        results = run_group_chat(\n",
    "            pattern=_pattern,\n",
    "            messages=__INITIAL_MSG__,\n",
    "            max_rounds=50,\n",
    "            pause_event=pause_event,\n",
    "        )\n",
    "        if not isinstance(results, list):\n",
    "            results = [results]  # pylint: disable=redefined-variable-type\n",
    "        got_agents = False\n",
    "        known_agents: list[ConversableAgent] = []\n",
    "        result_events: list[dict[str, Any]] = []\n",
    "        if on_event:\n",
    "            for index, result in enumerate(results):\n",
    "                result_events = []\n",
    "                for event in result.events:\n",
    "                    try:\n",
    "                        result_events.append(\n",
    "                            event.model_dump(mode=\"json\", fallback=str)\n",
    "                        )\n",
    "                    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "                        pass\n",
    "                    if not got_agents:\n",
    "                        known_agents = _get_known_agents()\n",
    "                        got_agents = True\n",
    "                    pause_event.clear()\n",
    "                    try:\n",
    "                        should_continue = on_event(event, known_agents)\n",
    "                        pause_event.set()\n",
    "                    except BaseException as e:\n",
    "                        stop_logging()\n",
    "                        store_error(e)\n",
    "                        raise SystemExit(\"Error in event handler: \" + str(e)) from e\n",
    "                    if getattr(event, \"type\") == \"run_completion\":\n",
    "                        break\n",
    "                    if not should_continue:\n",
    "                        stop_logging()\n",
    "                        store_error()\n",
    "                        raise SystemExit(\"Event handler stopped processing\")\n",
    "                result_cost = result.cost\n",
    "                result_context_variables = result.context_variables\n",
    "                result_dict = {\n",
    "                    \"index\": index,\n",
    "                    \"uuid\": str(result.uuid),\n",
    "                    \"events\": result_events,\n",
    "                    \"messages\": result.messages,\n",
    "                    \"summary\": result.summary,\n",
    "                    \"cost\": (\n",
    "                        result_cost.model_dump(mode=\"json\", fallback=str)\n",
    "                        if result_cost\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"context_variables\": (\n",
    "                        result_context_variables.model_dump(mode=\"json\", fallback=str)\n",
    "                        if result_context_variables\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"last_speaker\": result.last_speaker,\n",
    "                }\n",
    "                result_dicts.append(result_dict)\n",
    "        else:\n",
    "            for index, result in enumerate(results):\n",
    "                result_events = []\n",
    "                result.process()\n",
    "                for event in result.events:\n",
    "                    try:\n",
    "                        result_events.append(\n",
    "                            event.model_dump(mode=\"json\", fallback=str)\n",
    "                        )\n",
    "                    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "                        pass\n",
    "                result_cost = result.cost\n",
    "                result_context_variables = result.context_variables\n",
    "                result_dict = {\n",
    "                    \"index\": index,\n",
    "                    \"uuid\": str(result.uuid),\n",
    "                    \"events\": result_events,\n",
    "                    \"messages\": result.messages,\n",
    "                    \"summary\": result.summary,\n",
    "                    \"cost\": (\n",
    "                        result_cost.model_dump(mode=\"json\", fallback=str)\n",
    "                        if result_cost\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"context_variables\": (\n",
    "                        result_context_variables.model_dump(mode=\"json\", fallback=str)\n",
    "                        if result_context_variables\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"last_speaker\": result.last_speaker,\n",
    "                }\n",
    "                result_dicts.append(result_dict)\n",
    "\n",
    "        stop_logging()\n",
    "    store_results(result_dicts)\n",
    "    return result_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": false,
   "hide_notebook_metadata": true,
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
