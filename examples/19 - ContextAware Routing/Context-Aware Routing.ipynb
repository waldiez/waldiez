{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397eb6eb",
   "metadata": {},
   "source": [
    "# Name: Context-Aware Routing\n",
    "\n",
    "## Description: A waldiez implementation of AG2 example: https://docs.ag2.ai/latest/docs/user-guide/advanced-concepts/pattern-cookbook/context_aware_routing/\n",
    "The Context-Aware Routing Pattern creates a dynamic workflow where tasks are intelligently distributed to specialized agents based on content analysis rather than predetermined paths. Unlike static patterns with fixed routes, this approach analyzes each request in real-time to determine the most appropriate specialist, ensuring queries are handled by agents with the most relevant expertise while maintaining conversation continuity even as topics shift across domains.\n",
    "\n",
    "## Tags: \n",
    "\n",
    "###ğŸ§© generated with â¤ï¸ by Waldiez.\n",
    "\n",
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9be57a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# # !{sys.executable} -m pip install -q ag2[openai]==0.10.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e06122",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cabe84",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import csv\n",
    "import importlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "import sys\n",
    "import threading\n",
    "import traceback\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from types import ModuleType\n",
    "from typing import (\n",
    "    Annotated,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Coroutine,\n",
    "    Dict,\n",
    "    List,\n",
    "    Optional,\n",
    "    Set,\n",
    "    Tuple,\n",
    "    TypedDict,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "import autogen  # type: ignore\n",
    "from autogen import (\n",
    "    Agent,\n",
    "    Cache,\n",
    "    ChatResult,\n",
    "    ConversableAgent,\n",
    "    GroupChat,\n",
    "    UserProxyAgent,\n",
    "    register_function,\n",
    "    runtime_logging,\n",
    ")\n",
    "from autogen.agentchat import GroupChatManager, ReplyResult, run_group_chat\n",
    "from autogen.agentchat.group import (\n",
    "    AgentTarget,\n",
    "    ContextExpression,\n",
    "    ContextVariables,\n",
    "    ExpressionAvailableCondition,\n",
    "    ExpressionContextCondition,\n",
    "    OnContextCondition,\n",
    "    ReplyResult,\n",
    "    RevertToUserTarget,\n",
    ")\n",
    "from autogen.agentchat.group.patterns import DefaultPattern\n",
    "from autogen.agentchat.group.patterns.pattern import Pattern\n",
    "from autogen.agentchat.group.targets.transition_target import (\n",
    "    AgentNameTarget,\n",
    "    AgentTarget,\n",
    "    RevertToUserTarget,\n",
    ")\n",
    "from autogen.events import BaseEvent\n",
    "from autogen.io.run_response import (\n",
    "    AsyncRunResponseProtocol,\n",
    "    RunResponseProtocol,\n",
    ")\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Common environment variable setup for Waldiez flows\n",
    "load_dotenv(override=True)\n",
    "os.environ[\"AUTOGEN_USE_DOCKER\"] = \"0\"\n",
    "os.environ[\"TOGETHER_NO_BANNER\"] = \"1\"\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"False\"\n",
    "#\n",
    "# let's try to avoid:\n",
    "# module 'numpy' has no attribute '_no_nep50_warning'\"\n",
    "# ref: https://github.com/numpy/numpy/blob/v2.2.2/doc/source/release/2.2.0-notes.rst#nep-50-promotion-state-option-removed\n",
    "os.environ[\"NEP50_DEPRECATION_WARNING\"] = \"0\"\n",
    "os.environ[\"NEP50_DISABLE_WARNING\"] = \"1\"\n",
    "os.environ[\"NPY_PROMOTION_STATE\"] = \"weak\"\n",
    "if not hasattr(np, \"_no_pep50_warning\"):\n",
    "\n",
    "    import contextlib\n",
    "    from typing import Generator\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _np_no_nep50_warning() -> Generator[None, None, None]:\n",
    "        \"\"\"Dummy function to avoid the warning.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        None\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "        yield\n",
    "\n",
    "    setattr(np, \"_no_pep50_warning\", _np_no_nep50_warning)  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00913935",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb43fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_logging() -> None:\n",
    "    \"\"\"Start logging.\"\"\"\n",
    "    runtime_logging.start(\n",
    "        logger_type=\"sqlite\",\n",
    "        config={\"dbname\": \"flow.db\"},\n",
    "    )\n",
    "\n",
    "\n",
    "start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1598b0ee",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Load model API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e529edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# This section assumes that a file named:\n",
    "# \"context_aware_routin_api_keys.py\"\n",
    "# exists in the same directory as this file.\n",
    "# This file contains the API keys for the models used in this flow.\n",
    "# It should be .gitignored and not shared publicly.\n",
    "# If this file is not present, you can either create it manually\n",
    "# or change the way API keys are loaded in the flow.\n",
    "\n",
    "\n",
    "def load_api_key_module(flow_name: str) -> ModuleType:\n",
    "    \"\"\"Load the api key module.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flow_name : str\n",
    "        The flow name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ModuleType\n",
    "        The api keys loading module.\n",
    "    \"\"\"\n",
    "    module_name = f\"{flow_name}_api_keys\"\n",
    "    if module_name in sys.modules:\n",
    "        return importlib.reload(sys.modules[module_name])\n",
    "    return importlib.import_module(module_name)\n",
    "\n",
    "\n",
    "__MODELS_MODULE__ = load_api_key_module(\"context_aware_routin\")\n",
    "\n",
    "\n",
    "def get_context_aware_routin_model_api_key(model_name: str) -> str:\n",
    "    \"\"\"Get the model api key.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        The model name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The model api key.\n",
    "    \"\"\"\n",
    "    return __MODELS_MODULE__.get_context_aware_routin_model_api_key(model_name)\n",
    "\n",
    "\n",
    "class GroupDict(TypedDict):\n",
    "    \"\"\"Group related global dict.\"\"\"\n",
    "\n",
    "    chats: dict[str, GroupChat]\n",
    "    patterns: dict[str, Pattern]\n",
    "\n",
    "\n",
    "__GROUP__: GroupDict = {\"chats\": {}, \"patterns\": {}}\n",
    "\n",
    "__AGENTS__: dict[str, ConversableAgent] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c6badb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b024dd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def analyze_request(\n",
    "    request: Annotated[str, \"The user request text to analyze\"],\n",
    "    context_variables: ContextVariables,\n",
    ") -> ReplyResult:\n",
    "    \"\"\"\n",
    "    Analyze a user request to determine routing based on content\n",
    "    Updates context variables with routing information\n",
    "    \"\"\"\n",
    "    context_variables[\"question_answered\"] = False\n",
    "\n",
    "    # Update request tracking\n",
    "    context_variables[\"routing_started\"] = True\n",
    "    context_variables[\"request_count\"] += 1\n",
    "    context_variables[\"current_request\"] = request\n",
    "\n",
    "    # Previous domain becomes part of history\n",
    "    if context_variables[\"current_domain\"]:\n",
    "        prev_domain = context_variables[\"current_domain\"]\n",
    "        context_variables[\"previous_domains\"].append(prev_domain)\n",
    "        if prev_domain in context_variables[\"domain_history\"]:\n",
    "            context_variables[\"domain_history\"][prev_domain] += 1\n",
    "        else:\n",
    "            context_variables[\"domain_history\"][prev_domain] = 1\n",
    "\n",
    "    # Reset current_domain to be determined by the router\n",
    "    context_variables[\"current_domain\"] = None\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=f\"Request analyzed. Will determine the best specialist to handle: '{request}'\",\n",
    "        context_variables=context_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "def route_to_tech_specialist(\n",
    "    confidence: Annotated[int, \"Confidence level for tech domain (1-10)\"],\n",
    "    reasoning: Annotated[str, \"Reasoning for routing to tech specialist\"],\n",
    "    context_variables: ContextVariables,\n",
    ") -> ReplyResult:\n",
    "    \"\"\"\n",
    "    Route the current request to the technology specialist\n",
    "    \"\"\"\n",
    "    context_variables[\"current_domain\"] = \"technology\"\n",
    "    context_variables[\"domain_confidence\"][\"technology\"] = confidence\n",
    "    context_variables[\"tech_invocations\"] += 1\n",
    "\n",
    "    return ReplyResult(\n",
    "        target=AgentTarget(agent=tech_specialist),\n",
    "        message=f\"Routing to tech specialist with confidence {confidence}/10. Reasoning: {reasoning}\",\n",
    "        context_variables=context_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "def route_to_finance_specialist(\n",
    "    confidence: Annotated[int, \"Confidence level for finance domain (1-10)\"],\n",
    "    reasoning: Annotated[str, \"Reasoning for routing to finance specialist\"],\n",
    "    context_variables: ContextVariables,\n",
    ") -> ReplyResult:\n",
    "    \"\"\"\n",
    "    Route the current request to the finance specialist\n",
    "    \"\"\"\n",
    "    context_variables[\"current_domain\"] = \"finance\"\n",
    "    context_variables[\"domain_confidence\"][\"finance\"] = confidence\n",
    "    context_variables[\"finance_invocations\"] += 1\n",
    "\n",
    "    return ReplyResult(\n",
    "        # target=AgentTarget(finance_specialist),\n",
    "        target=AgentNameTarget(agent_name=\"finance_specialist\"),\n",
    "        message=f\"Routing to finance specialist with confidence {confidence}/10. Reasoning: {reasoning}\",\n",
    "        context_variables=context_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "def route_to_healthcare_specialist(\n",
    "    confidence: Annotated[int, \"Confidence level for healthcare domain (1-10)\"],\n",
    "    reasoning: Annotated[str, \"Reasoning for routing to healthcare specialist\"],\n",
    "    context_variables: ContextVariables,\n",
    ") -> ReplyResult:\n",
    "    \"\"\"\n",
    "    Route the current request to the healthcare specialist\n",
    "    \"\"\"\n",
    "    context_variables[\"current_domain\"] = \"healthcare\"\n",
    "    context_variables[\"domain_confidence\"][\"healthcare\"] = confidence\n",
    "    context_variables[\"healthcare_invocations\"] += 1\n",
    "\n",
    "    return ReplyResult(\n",
    "        target=AgentTarget(agent=healthcare_specialist),\n",
    "        message=f\"Routing to healthcare specialist with confidence {confidence}/10. Reasoning: {reasoning}\",\n",
    "        context_variables=context_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "def route_to_general_specialist(\n",
    "    confidence: Annotated[int, \"Confidence level for general domain (1-10)\"],\n",
    "    reasoning: Annotated[\n",
    "        str, \"Reasoning for routing to general knowledge specialist\"\n",
    "    ],\n",
    "    context_variables: ContextVariables,\n",
    ") -> ReplyResult:\n",
    "    \"\"\"\n",
    "    Route the current request to the general knowledge specialist\n",
    "    \"\"\"\n",
    "    context_variables[\"current_domain\"] = \"general\"\n",
    "    context_variables[\"domain_confidence\"][\"general\"] = confidence\n",
    "    context_variables[\"general_invocations\"] += 1\n",
    "\n",
    "    return ReplyResult(\n",
    "        target=AgentTarget(agent=general_specialist),\n",
    "        message=f\"Routing to general knowledge specialist with confidence {confidence}/10. Reasoning: {reasoning}\",\n",
    "        context_variables=context_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "def provide_tech_response(\n",
    "    response: Annotated[str, \"The specialist's response to the request\"],\n",
    "    context_variables: ContextVariables,\n",
    ") -> ReplyResult:\n",
    "    \"\"\"\n",
    "    Submit a response from the technology specialist\n",
    "    \"\"\"\n",
    "    # Record the question and response\n",
    "    context_variables[\"question_responses\"].append(\n",
    "        {\n",
    "            \"domain\": \"technology\",\n",
    "            \"question\": context_variables[\"current_request\"],\n",
    "            \"response\": response,\n",
    "        }\n",
    "    )\n",
    "    context_variables[\"question_answered\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"Technology specialist response provided.\",\n",
    "        context_variables=context_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "def provide_finance_response(\n",
    "    response: Annotated[str, \"The specialist's response to the request\"],\n",
    "    context_variables: ContextVariables,\n",
    ") -> ReplyResult:\n",
    "    \"\"\"\n",
    "    Submit a response from the finance specialist\n",
    "    \"\"\"\n",
    "    # Record the question and response\n",
    "    context_variables[\"question_responses\"].append(\n",
    "        {\n",
    "            \"domain\": \"finance\",\n",
    "            \"question\": context_variables[\"current_request\"],\n",
    "            \"response\": response,\n",
    "        }\n",
    "    )\n",
    "    context_variables[\"question_answered\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"Finance specialist response provided.\",\n",
    "        context_variables=context_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "def provide_healthcare_response(\n",
    "    response: Annotated[str, \"The specialist's response to the request\"],\n",
    "    context_variables: ContextVariables,\n",
    ") -> ReplyResult:\n",
    "    \"\"\"\n",
    "    Submit a response from the healthcare specialist\n",
    "    \"\"\"\n",
    "    # Record the question and response\n",
    "    context_variables[\"question_responses\"].append(\n",
    "        {\n",
    "            \"domain\": \"healthcare\",\n",
    "            \"question\": context_variables[\"current_request\"],\n",
    "            \"response\": response,\n",
    "        }\n",
    "    )\n",
    "    context_variables[\"question_answered\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"Healthcare specialist response provided.\",\n",
    "        context_variables=context_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "def provide_general_response(\n",
    "    response: Annotated[str, \"The specialist's response to the request\"],\n",
    "    context_variables: ContextVariables,\n",
    ") -> ReplyResult:\n",
    "    \"\"\"\n",
    "    Submit a response from the general knowledge specialist\n",
    "    \"\"\"\n",
    "    # Record the question and response\n",
    "    context_variables[\"question_responses\"].append(\n",
    "        {\n",
    "            \"domain\": \"general\",\n",
    "            \"question\": context_variables[\"current_request\"],\n",
    "            \"response\": response,\n",
    "        }\n",
    "    )\n",
    "    context_variables[\"question_answered\"] = True\n",
    "\n",
    "    return ReplyResult(\n",
    "        message=\"General knowledge specialist response provided.\",\n",
    "        context_variables=context_variables,\n",
    "    )\n",
    "\n",
    "\n",
    "# Function for follow-up clarification if needed\n",
    "def request_clarification(\n",
    "    clarification_question: Annotated[\n",
    "        str, \"Question to ask user for clarification\"\n",
    "    ],\n",
    "    context_variables: ContextVariables,\n",
    ") -> ReplyResult:\n",
    "    \"\"\"\n",
    "    Request clarification from the user when the query is ambiguous\n",
    "    \"\"\"\n",
    "    return ReplyResult(\n",
    "        message=f\"Further clarification is required to determine the correct domain: {clarification_question}\",\n",
    "        context_variables=context_variables,\n",
    "        target=RevertToUserTarget(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb424d1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_1_mini_llm_config: dict[str, Any] = {\n",
    "    \"model\": \"gpt-4.1-mini\",\n",
    "    \"api_type\": \"openai\",\n",
    "    \"api_key\": get_context_aware_routin_model_api_key(\"gpt_4_1_mini\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a173cb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527efd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "User = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    description=\"A new User agent\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    llm_config=False,\n",
    ")\n",
    "\n",
    "__AGENTS__[\"User\"] = User\n",
    "\n",
    "finance_specialist = ConversableAgent(\n",
    "    name=\"finance_specialist\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are the finance specialist with deep expertise in personal finance, investments, banking, budgeting, financial planning, taxes, economics, and business finance.\\n\\n    When responding to queries in your domain:\\n    1. Provide accurate financial information and advice based on sound financial principles\\n    2. Explain financial concepts clearly without excessive jargon\\n    3. Present balanced perspectives on financial decisions, acknowledging risks and benefits\\n    4. Avoid making specific investment recommendations but provide educational information about investment types\\n    5. Include relevant financial principles, terms, or calculations when appropriate\\n\\n    Focus on being informative, balanced, and helpful. If a query contains elements outside your domain of expertise, focus on the financial aspects while acknowledging the broader context.\\n\\n    Use the provide_finance_response tool to submit your final response.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        provide_finance_response,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_1_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"finance_specialist\"] = finance_specialist\n",
    "\n",
    "general_specialist = ConversableAgent(\n",
    "    name=\"general_specialist\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are the general knowledge specialist with broad expertise across multiple domains and topics.\\n\\n    When responding to queries in your domain:\\n    1. Provide comprehensive information drawing from relevant knowledge domains\\n    2. Handle questions that span multiple domains or don't clearly fit into a specialized area\\n    3. Synthesize information from different fields when appropriate\\n    4. Provide balanced perspectives on complex topics\\n    5. Address queries about history, culture, society, ethics, environment, education, arts, and other general topics\\n\\n    Focus on being informative, balanced, and helpful. For questions that might benefit from deeper domain expertise, acknowledge this while providing the best general information possible.\\n\\n    Use the provide_general_response tool to submit your final response.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        provide_general_response,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_1_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"general_specialist\"] = general_specialist\n",
    "\n",
    "healthcare_specialist = ConversableAgent(\n",
    "    name=\"healthcare_specialist\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are the healthcare specialist with deep expertise in health, medicine, fitness, nutrition, diseases, medical conditions, and wellness.\\n\\n    When responding to queries in your domain:\\n    1. Provide accurate health information based on current medical understanding\\n    2. Explain medical concepts in clear, accessible language\\n    3. Include preventive advice and best practices for health management when appropriate\\n    4. Reference relevant health principles, systems, or processes\\n    5. Always clarify that you're providing general information, not personalized medical advice\\n\\n    Focus on being informative, accurate, and helpful. If a query contains elements outside your domain of expertise, focus on the health aspects while acknowledging the broader context.\\n\\n    Use the provide_healthcare_response tool to submit your final response.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        provide_healthcare_response,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_1_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"healthcare_specialist\"] = healthcare_specialist\n",
    "\n",
    "router_agent = ConversableAgent(\n",
    "    name=\"router_agent\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are the routing agent responsible for analyzing user requests and directing them to the most appropriate specialist.\\n\\n    Your task is to carefully analyze each user query and determine which domain specialist would be best equipped to handle it:\\n\\n    1. Technology Specialist: For questions about computers, software, programming, IT issues, electronics, digital tools, internet, etc. Use route_to_tech_specialist to transfer.\\n    2. Finance Specialist: For questions about money, investments, banking, budgeting, financial planning, taxes, economics, etc. Use route_to_finance_specialist to transfer.\\n    3. Healthcare Specialist: For questions about health, medicine, fitness, nutrition, diseases, medical conditions, wellness, etc. Use route_to_healthcare_specialist to transfer.\\n    4. General Knowledge Specialist: For general questions that don't clearly fit the other categories or span multiple domains. Use route_to_general_specialist to transfer.\\n\\n    For each query, you must:\\n    1. Use the analyze_request tool to process the query and update context\\n    2. Determine the correct domain by analyzing keywords, themes, and context\\n    3. Consider the conversation history and previous domains if available\\n    4. Route to the most appropriate specialist using the corresponding routing tool\\n\\n    When routing:\\n    - Provide a confidence level (1-10) based on how certain you are about the domain\\n    - Include detailed reasoning for your routing decision\\n    - If a query seems ambiguous or spans multiple domains, route to the specialist who can best handle the primary intent\\n\\n    Always maintain context awareness by considering:\\n    - Current query content and intent\\n    - Previously discussed topics\\n    - User's possible follow-up patterns\\n    - Domain switches that might indicate changing topics\\n\\n    After a specialist has provided an answer, output the question and answer.\\n\\n    For ambiguous queries that could belong to multiple domains:\\n    - If you are CERTAIN that the query is multi-domain but has a primary focus, route to the specialist for that primary domain\\n    - If you are NOT CERTAIN and there is no clear primary domain, use the request_clarification tool to ask the user for more specifics\\n    - When a query follows up on a previous topic, consider maintaining consistency by routing to the same specialist unless the domain has clearly changed\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        analyze_request,\n",
    "        route_to_finance_specialist,\n",
    "        route_to_healthcare_specialist,\n",
    "        route_to_tech_specialist,\n",
    "        route_to_general_specialist,\n",
    "        request_clarification,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_1_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"router_agent\"] = router_agent\n",
    "\n",
    "tech_specialist = ConversableAgent(\n",
    "    name=\"tech_specialist\",\n",
    "    description=\"A new Assistant agent\",\n",
    "    system_message=\"You are the technology specialist with deep expertise in computers, software, programming, IT, electronics, digital tools, and internet technologies.\\n\\n    When responding to queries in your domain:\\n    1. Provide accurate, technical information based on current industry knowledge\\n    2. Explain complex concepts in clear terms appropriate for the user's apparent level of technical understanding\\n    3. Include practical advice, troubleshooting steps, or implementation guidance when applicable\\n    4. Reference relevant technologies, programming languages, frameworks, or tools as appropriate\\n    5. For coding questions, provide correct, well-structured code examples when helpful\\n\\n    Focus on being informative, precise, and helpful. If a query contains elements outside your domain of expertise, focus on the technology aspects while acknowledging the broader context.\\n\\n    Use the provide_tech_response tool to submit your final response.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,\n",
    "    functions=[\n",
    "        provide_tech_response,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_1_mini_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "__AGENTS__[\"tech_specialist\"] = tech_specialist\n",
    "\n",
    "finance_specialist.handoffs.set_after_work(target=AgentTarget(router_agent))\n",
    "\n",
    "general_specialist.handoffs.set_after_work(target=AgentTarget(router_agent))\n",
    "\n",
    "healthcare_specialist.handoffs.set_after_work(target=AgentTarget(router_agent))\n",
    "\n",
    "router_agent.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(tech_specialist),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"${current_domain} == 'technology'\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"!${question_answered}\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "router_agent.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(finance_specialist),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"${current_domain} == 'finance'\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"!${question_answered}\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "router_agent.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(healthcare_specialist),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"${current_domain} == 'healthcare'\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"!${question_answered}\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "router_agent.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(general_specialist),\n",
    "        condition=ExpressionContextCondition(\n",
    "            expression=ContextExpression(\"${current_domain} == 'general'\")\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"!${question_answered}\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "router_agent.handoffs.set_after_work(target=RevertToUserTarget())\n",
    "\n",
    "tech_specialist.handoffs.set_after_work(target=AgentTarget(router_agent))\n",
    "\n",
    "__INITIAL_MSG__ = \"I have a question. Can you tell me about benefits? I'm trying to understand all my options and make the right decision.\"\n",
    "\n",
    "_pattern = DefaultPattern(\n",
    "    initial_agent=router_agent,\n",
    "    agents=[\n",
    "        router_agent,\n",
    "        tech_specialist,\n",
    "        finance_specialist,\n",
    "        healthcare_specialist,\n",
    "        general_specialist,\n",
    "    ],\n",
    "    user_agent=User,\n",
    "    group_manager_args={\n",
    "        \"llm_config\": False,\n",
    "        \"name\": \"\",\n",
    "    },\n",
    "    context_variables=ContextVariables(\n",
    "        data={\n",
    "            \"routing_started\": False,\n",
    "            \"current_domain\": None,\n",
    "            \"previous_domains\": [],\n",
    "            \"domain_confidence\": {},\n",
    "            \"request_count\": 0,\n",
    "            \"current_request\": \"\",\n",
    "            \"domain_history\": {},\n",
    "            \"question_responses\": [],\n",
    "            \"question_answered\": True,\n",
    "            \"tech_invocations\": 0,\n",
    "            \"finance_invocations\": 0,\n",
    "            \"healthcare_invocations\": 0,\n",
    "            \"general_invocations\": 0,\n",
    "            \"has_error\": False,\n",
    "            \"error_message\": \"\",\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "__GROUP__[\"patterns\"][\"_pattern\"] = _pattern\n",
    "\n",
    "\n",
    "def get_sqlite_out(dbname: str, table: str, csv_file: str) -> None:\n",
    "    \"\"\"Convert a sqlite table to csv and json files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dbname : str\n",
    "        The sqlite database name.\n",
    "    table : str\n",
    "        The table name.\n",
    "    csv_file : str\n",
    "        The csv file name.\n",
    "    \"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements\n",
    "    try:\n",
    "        conn = sqlite3.connect(dbname)\n",
    "    except BaseException:\n",
    "        return\n",
    "    query = f\"SELECT * FROM {table}\"  # nosec\n",
    "    try:\n",
    "        cursor = conn.execute(query)\n",
    "    except BaseException:\n",
    "        conn.close()\n",
    "        return\n",
    "    try:\n",
    "        rows = cursor.fetchall()\n",
    "        column_names = [description[0] for description in cursor.description]\n",
    "        data = [dict(zip(column_names, row, strict=True)) for row in rows]\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "    except BaseException:\n",
    "        try:\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "        except BaseException:\n",
    "            pass\n",
    "        return\n",
    "    try:\n",
    "        with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            csv_writer = csv.DictWriter(file, fieldnames=column_names)\n",
    "            csv_writer.writeheader()\n",
    "            csv_writer.writerows(data)\n",
    "        json_file = csv_file.replace(\".csv\", \".json\")\n",
    "        with open(json_file, \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "            json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "    except BaseException:\n",
    "        return\n",
    "\n",
    "\n",
    "def stop_logging() -> None:\n",
    "    \"\"\"Stop logging.\"\"\"\n",
    "    runtime_logging.stop()\n",
    "    if not os.path.exists(\"logs\"):\n",
    "        try:\n",
    "            os.makedirs(\"logs\", exist_ok=True)\n",
    "        except BaseException:\n",
    "            pass\n",
    "    for table in [\n",
    "        \"chat_completions\",\n",
    "        \"agents\",\n",
    "        \"oai_wrappers\",\n",
    "        \"oai_clients\",\n",
    "        \"version\",\n",
    "        \"events\",\n",
    "        \"function_calls\",\n",
    "    ]:\n",
    "        dest = os.path.join(\"logs\", f\"{table}.csv\")\n",
    "        get_sqlite_out(\"flow.db\", table, dest)\n",
    "\n",
    "\n",
    "def _check_for_extra_agents(agent: ConversableAgent) -> list[ConversableAgent]:\n",
    "    _extra_agents: list[ConversableAgent] = []\n",
    "    _agent_cls_name = agent.__class__.__name__\n",
    "    if _agent_cls_name == \"CaptainAgent\":\n",
    "        _assistant_agent = getattr(agent, \"assistant\", None)\n",
    "        if _assistant_agent and _assistant_agent not in _extra_agents:\n",
    "            _extra_agents.append(_assistant_agent)\n",
    "        _executor_agent = getattr(agent, \"executor\", None)\n",
    "        if _executor_agent and _executor_agent not in _extra_agents:\n",
    "            _extra_agents.append(_executor_agent)\n",
    "    return _extra_agents\n",
    "\n",
    "\n",
    "def _check_for_group_members(agent: ConversableAgent) -> list[ConversableAgent]:\n",
    "    _extra_agents: list[ConversableAgent] = []\n",
    "    _group_chat = getattr(agent, \"_groupchat\", None)\n",
    "    if _group_chat:\n",
    "        _chat_agents = getattr(_group_chat, \"agents\", [])\n",
    "        if isinstance(_chat_agents, list):\n",
    "            for _group_member in _chat_agents:\n",
    "                if _group_member not in _extra_agents:\n",
    "                    _extra_agents.append(_group_member)\n",
    "    _manager = getattr(agent, \"_group_manager\", None)\n",
    "    if _manager:\n",
    "        if _manager not in _extra_agents:\n",
    "            _extra_agents.append(_manager)\n",
    "        for _group_member in _check_for_group_members(_manager):\n",
    "            if _group_member not in _extra_agents:\n",
    "                _extra_agents.append(_group_member)\n",
    "    return _extra_agents\n",
    "\n",
    "\n",
    "def _get_known_agents() -> list[ConversableAgent]:\n",
    "    _known_agents: list[ConversableAgent] = []\n",
    "    if User not in _known_agents:\n",
    "        _known_agents.append(User)\n",
    "    _known_agents.append(User)\n",
    "    for _group_member in _check_for_group_members(User):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(User):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if router_agent not in _known_agents:\n",
    "        _known_agents.append(router_agent)\n",
    "    _known_agents.append(router_agent)\n",
    "    for _group_member in _check_for_group_members(router_agent):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(router_agent):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if tech_specialist not in _known_agents:\n",
    "        _known_agents.append(tech_specialist)\n",
    "    _known_agents.append(tech_specialist)\n",
    "    for _group_member in _check_for_group_members(tech_specialist):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(tech_specialist):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if finance_specialist not in _known_agents:\n",
    "        _known_agents.append(finance_specialist)\n",
    "    _known_agents.append(finance_specialist)\n",
    "    for _group_member in _check_for_group_members(finance_specialist):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(finance_specialist):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if healthcare_specialist not in _known_agents:\n",
    "        _known_agents.append(healthcare_specialist)\n",
    "    _known_agents.append(healthcare_specialist)\n",
    "    for _group_member in _check_for_group_members(healthcare_specialist):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(healthcare_specialist):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "\n",
    "    if general_specialist not in _known_agents:\n",
    "        _known_agents.append(general_specialist)\n",
    "    _known_agents.append(general_specialist)\n",
    "    for _group_member in _check_for_group_members(general_specialist):\n",
    "        if _group_member not in _known_agents:\n",
    "            _known_agents.append(_group_member)\n",
    "    for _extra_agent in _check_for_extra_agents(general_specialist):\n",
    "        if _extra_agent not in _known_agents:\n",
    "            _known_agents.append(_extra_agent)\n",
    "    return _known_agents\n",
    "\n",
    "\n",
    "def store_error(exc: BaseException | None = None) -> None:\n",
    "    \"\"\"Store the error in error.json.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exc : BaseException | None\n",
    "        The exception we got if any.\n",
    "    \"\"\"\n",
    "    reason = (\n",
    "        \"Event handler stopped processing\"\n",
    "        if not exc\n",
    "        else traceback.format_exc()\n",
    "    )\n",
    "    try:\n",
    "        with open(\"error.json\", \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "            file.write(json.dumps({\"error\": reason}))\n",
    "    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "        pass\n",
    "\n",
    "\n",
    "def store_results(result_dicts: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Store the results to results.json.\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_dicts : list[dict[str, Any]]\n",
    "        The list of the results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(\"results.json\", \"w\", encoding=\"utf-8\", newline=\"\\n\") as file:\n",
    "            file.write(\n",
    "                json.dumps(\n",
    "                    {'results': result_dicts}, indent=4, ensure_ascii=False\n",
    "                )\n",
    "            )\n",
    "    except BaseException:  # pylint: disable=broad-exception-caught\n",
    "        pass\n",
    "\n",
    "\n",
    "def _get_agent_by_name(\n",
    "    agents: list[ConversableAgent], agent_name: str\n",
    ") -> tuple[int, ConversableAgent | None]:\n",
    "    \"\"\"Get an agent by its name.\"\"\"\n",
    "    for ind, agent in enumerate(agents):\n",
    "        if agent.name == agent_name:\n",
    "            return ind, agent\n",
    "    return -1, None\n",
    "\n",
    "\n",
    "def _handle_resume_group_pattern(\n",
    "    detected_pattern: Pattern, state_messages: list[dict[str, Any]]\n",
    ") -> None:\n",
    "    \"\"\"Handle detected pattern for resuming a group chat.\"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements\n",
    "    try:\n",
    "        _pattern_type = getattr(detected_pattern.__class__, \"__name__\", None)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if _pattern_type == \"RoundRobinPattern\" and state_messages:\n",
    "        last_message = state_messages[-1]\n",
    "        if not last_message or not isinstance(last_message, dict):\n",
    "            return\n",
    "        last_agent_name = last_message.get(\"name\", \"\")\n",
    "        if not last_agent_name:\n",
    "            return\n",
    "        try:\n",
    "            idx, last_agent = _get_agent_by_name(\n",
    "                detected_pattern.agents, last_agent_name\n",
    "            )\n",
    "            if last_agent and len(detected_pattern.agents) >= (idx + 1):\n",
    "                detected_pattern.agents.append(detected_pattern.user_agent)\n",
    "                detected_pattern.initial_agent = detected_pattern.agents[\n",
    "                    idx + 1\n",
    "                ]\n",
    "                detected_pattern.user_agent = detected_pattern.agents[idx]\n",
    "                # fmt: off\n",
    "                new_agent_order_list = detected_pattern.agents[idx+1:] + detected_pattern.agents[:idx]\n",
    "                # fmt: on\n",
    "                detected_pattern.agents = new_agent_order_list\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "\n",
    "def _prepare_resume(state_json: str | Path | None = None) -> None:\n",
    "    \"\"\"Prepare resuming a chat from state.json.\n",
    "\n",
    "    state.json format:\n",
    "        {\n",
    "            \"messages\": [{\"content\": \"..\", \"role\": \"...\", \"name\": \"...\"}],\n",
    "            \"context_variables\": {\"key1\": \"value1\", \"key2\": 4, \"key3\": [], \"key4\": {\"other\": \"key\"}}\n",
    "        }\n",
    "    metadata.json format:\n",
    "        {\n",
    "            \"type\": \"group\",\n",
    "            \"group\": {  # one of:\n",
    "                \"pattern\" : \"<pattern_name>\",\n",
    "                \"manager\" : \"<manager_name>\",\n",
    "            }\n",
    "        }\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state_json : str | Path | None\n",
    "        The path to state.json to load previous state.\n",
    "    \"\"\"\n",
    "    # pylint: disable=broad-exception-caught,too-many-try-statements,global-statement\n",
    "    global __INITIAL_MSG__\n",
    "    if not state_json or not Path(state_json).is_file():\n",
    "        return\n",
    "    metadata_json = str(state_json).replace(\"state.json\", \"metadata.json\")\n",
    "    if not metadata_json or not Path(metadata_json).is_file():\n",
    "        return\n",
    "    try:\n",
    "        with open(metadata_json, \"r\", encoding=\"utf-8\") as f:\n",
    "            _metadata_dict = json.load(f)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if not _metadata_dict or not isinstance(_metadata_dict, dict):\n",
    "        return\n",
    "    _state_chat_type = _metadata_dict.get(\"type\", \"\")\n",
    "    if _state_chat_type != \"group\":\n",
    "        # only resume group chats\n",
    "        return\n",
    "    _state_group_details = _metadata_dict.get(\"group\", {})\n",
    "    if not _state_group_details or not isinstance(_state_group_details, dict):\n",
    "        return\n",
    "    # either pattern or manager\n",
    "    _state_group_pattern = _state_group_details.get(\"pattern\", \"\")\n",
    "    _state_group_manager = _state_group_details.get(\"manager\", \"\")\n",
    "    if not _state_group_pattern and not _state_group_manager:\n",
    "        return\n",
    "    try:\n",
    "        with open(state_json, \"r\", encoding=\"utf-8\") as f:\n",
    "            _state_dict = json.load(f)\n",
    "    except BaseException:\n",
    "        return\n",
    "    if not _state_dict or not isinstance(_state_dict, dict):\n",
    "        return\n",
    "    _state_messages = _state_dict.get(\"messages\", [])\n",
    "    _detected_pattern = None\n",
    "    if _state_group_pattern and isinstance(_state_group_pattern, str):\n",
    "        _detected_pattern = __GROUP__[\"patterns\"].get(\n",
    "            _state_group_pattern, None\n",
    "        )\n",
    "        if _detected_pattern:\n",
    "            _state_context_variables = _state_dict.get(\"context_variables\", {})\n",
    "            if _state_context_variables and isinstance(\n",
    "                _state_context_variables, dict\n",
    "            ):\n",
    "                _new_context_variables = (\n",
    "                    _detected_pattern.context_variables.data.copy()\n",
    "                )\n",
    "                _new_context_variables.update(_state_context_variables)\n",
    "                _detected_pattern.context_variables = ContextVariables(\n",
    "                    data=_new_context_variables\n",
    "                )\n",
    "        if _state_messages and isinstance(_state_messages, list):\n",
    "            __INITIAL_MSG__ = _state_messages\n",
    "    elif _state_group_manager and isinstance(_state_group_manager, str):\n",
    "        _known_group_manager = __AGENTS__.get(_state_group_manager, None)\n",
    "        if _known_group_manager and hasattr(_known_group_manager, \"groupchat\"):\n",
    "            if _state_messages and isinstance(_state_messages, list):\n",
    "                _known_group_manager.groupchat.messages = _state_messages\n",
    "        else:\n",
    "            _detected_pattern = __GROUP__[\"patterns\"].get(\n",
    "                f\"{_state_group_manager}_pattern\"\n",
    "            )\n",
    "            if _detected_pattern:\n",
    "                _state_context_variables = _state_dict.get(\n",
    "                    \"context_variables\", {}\n",
    "                )\n",
    "                if _state_context_variables and isinstance(\n",
    "                    _state_context_variables, dict\n",
    "                ):\n",
    "                    _new_context_variables = (\n",
    "                        _detected_pattern.context_variables.data.copy()\n",
    "                    )\n",
    "                    _new_context_variables.update(_state_context_variables)\n",
    "                    _detected_pattern.context_variables = ContextVariables(\n",
    "                        data=_new_context_variables\n",
    "                    )\n",
    "            if _state_messages and isinstance(_state_messages, list):\n",
    "                __INITIAL_MSG__ = _state_messages\n",
    "    if (\n",
    "        _detected_pattern\n",
    "        and _state_messages\n",
    "        and isinstance(_state_messages, list)\n",
    "    ):\n",
    "        _handle_resume_group_pattern(_detected_pattern, _state_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec65f530",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7b0c6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main(\n",
    "    on_event: Callable[[BaseEvent, list[ConversableAgent]], bool] | None = None,\n",
    "    state_json: str | Path | None = None,\n",
    ") -> list[dict[str, Any]]:\n",
    "    \"\"\"Start chatting.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict[str, Any]]\n",
    "        The result of the chat session.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    SystemExit\n",
    "        If the user interrupts the chat session.\n",
    "    \"\"\"\n",
    "    if state_json:\n",
    "        _prepare_resume(state_json)\n",
    "    results: list[RunResponseProtocol] | RunResponseProtocol = []\n",
    "    result_dicts: list[dict[str, Any]] = []\n",
    "    a_pause_event = asyncio.Event()\n",
    "    a_pause_event.set()\n",
    "    pause_event = threading.Event()\n",
    "    pause_event.set()\n",
    "    with Cache.disk(cache_seed=42) as cache:\n",
    "        results = run_group_chat(\n",
    "            pattern=_pattern,\n",
    "            messages=__INITIAL_MSG__,\n",
    "            max_rounds=100,\n",
    "            pause_event=pause_event,\n",
    "        )\n",
    "        if not isinstance(results, list):\n",
    "            results = [results]  # pylint: disable=redefined-variable-type\n",
    "        got_agents = False\n",
    "        known_agents: list[ConversableAgent] = []\n",
    "        result_events: list[dict[str, Any]] = []\n",
    "        if on_event:\n",
    "            for index, result in enumerate(results):\n",
    "                result_events = []\n",
    "                for event in result.events:\n",
    "                    try:\n",
    "                        result_events.append(\n",
    "                            event.model_dump(mode=\"json\", fallback=str)\n",
    "                        )\n",
    "                    except (\n",
    "                        BaseException\n",
    "                    ):  # pylint: disable=broad-exception-caught\n",
    "                        pass\n",
    "                    if not got_agents:\n",
    "                        known_agents = _get_known_agents()\n",
    "                        got_agents = True\n",
    "                    pause_event.clear()\n",
    "                    try:\n",
    "                        should_continue = on_event(event, known_agents)\n",
    "                        pause_event.set()\n",
    "                    except BaseException as e:\n",
    "                        stop_logging()\n",
    "                        store_error(e)\n",
    "                        raise SystemExit(\n",
    "                            \"Error in event handler: \" + str(e)\n",
    "                        ) from e\n",
    "                    if getattr(event, \"type\") == \"run_completion\":\n",
    "                        break\n",
    "                    if not should_continue:\n",
    "                        stop_logging()\n",
    "                        store_error()\n",
    "                        raise SystemExit(\"Event handler stopped processing\")\n",
    "                result_cost = result.cost\n",
    "                result_context_variables = result.context_variables\n",
    "                result_dict = {\n",
    "                    \"index\": index,\n",
    "                    \"uuid\": str(result.uuid),\n",
    "                    \"events\": result_events,\n",
    "                    \"messages\": result.messages,\n",
    "                    \"summary\": result.summary,\n",
    "                    \"cost\": (\n",
    "                        result_cost.model_dump(mode=\"json\", fallback=str)\n",
    "                        if result_cost\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"context_variables\": (\n",
    "                        result_context_variables.model_dump(\n",
    "                            mode=\"json\", fallback=str\n",
    "                        )\n",
    "                        if result_context_variables\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"last_speaker\": result.last_speaker,\n",
    "                }\n",
    "                result_dicts.append(result_dict)\n",
    "        else:\n",
    "            for index, result in enumerate(results):\n",
    "                result_events = []\n",
    "                # result.process()\n",
    "                for event in result.events:\n",
    "                    try:\n",
    "                        result_events.append(\n",
    "                            event.model_dump(mode=\"json\", fallback=str)\n",
    "                        )\n",
    "                    except (\n",
    "                        BaseException\n",
    "                    ):  # pylint: disable=broad-exception-caught\n",
    "                        pass\n",
    "                result_cost = result.cost\n",
    "                result_context_variables = result.context_variables\n",
    "                result_dict = {\n",
    "                    \"index\": index,\n",
    "                    \"uuid\": str(result.uuid),\n",
    "                    \"events\": result_events,\n",
    "                    \"messages\": result.messages,\n",
    "                    \"summary\": result.summary,\n",
    "                    \"cost\": (\n",
    "                        result_cost.model_dump(mode=\"json\", fallback=str)\n",
    "                        if result_cost\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"context_variables\": (\n",
    "                        result_context_variables.model_dump(\n",
    "                            mode=\"json\", fallback=str\n",
    "                        )\n",
    "                        if result_context_variables\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"last_speaker\": result.last_speaker,\n",
    "                }\n",
    "                result_dicts.append(result_dict)\n",
    "\n",
    "        stop_logging()\n",
    "    store_results(result_dicts)\n",
    "    return result_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1557f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": false,
   "hide_notebook_metadata": true,
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
