{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58a858f1",
   "metadata": {},
   "source": [
    "# Name: Swarm\n",
    "\n",
    "## Description: Enhanced Swarm Orchestration with AG2. Based on <https://docs.ag2.ai/latest/docs/use-cases/notebooks/notebooks/agentchat_swarm_enhanced>\n",
    "\n",
    "## Tags: Swarm, Group\n",
    "\n",
    "###ðŸ§© generated with â¤ï¸ by Waldiez.\n",
    "\n",
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440adce",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys  # pyright: ignore\n",
    "\n",
    "# # !{sys.executable} -m pip install -q ag2[openai]==0.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed705e0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9af23",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# pyright: reportUnusedImport=false,reportMissingTypeStubs=false\n",
    "import csv\n",
    "import importlib\n",
    "import json\n",
    "import os\n",
    "import sqlite3\n",
    "import sys\n",
    "from dataclasses import asdict\n",
    "from pprint import pprint\n",
    "from types import ModuleType\n",
    "from typing import (\n",
    "    Annotated,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    List,\n",
    "    Optional,\n",
    "    Set,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "import autogen  # type: ignore\n",
    "from autogen import (\n",
    "    Agent,\n",
    "    AssistantAgent,\n",
    "    Cache,\n",
    "    ChatResult,\n",
    "    ConversableAgent,\n",
    "    GroupChat,\n",
    "    UpdateSystemMessage,\n",
    "    UserProxyAgent,\n",
    "    register_function,\n",
    "    runtime_logging,\n",
    ")\n",
    "from autogen.agentchat import GroupChatManager, initiate_group_chat\n",
    "from autogen.agentchat.group import (\n",
    "    AgentNameTarget,\n",
    "    AgentTarget,\n",
    "    ContextExpression,\n",
    "    ContextVariables,\n",
    "    ExpressionAvailableCondition,\n",
    "    NestedChatTarget,\n",
    "    OnCondition,\n",
    "    OnContextCondition,\n",
    "    ReplyResult,\n",
    "    RevertToUserTarget,\n",
    "    StringAvailableCondition,\n",
    "    StringContextCondition,\n",
    "    StringLLMCondition,\n",
    ")\n",
    "from autogen.agentchat.group.patterns import DefaultPattern\n",
    "from autogen.coding import LocalCommandLineCodeExecutor\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "# let's try to avoid:\n",
    "# module 'numpy' has no attribute '_no_nep50_warning'\"\n",
    "# ref: https://github.com/numpy/numpy/blob/v2.2.2/doc/source/release/2.2.0-notes.rst#nep-50-promotion-state-option-removed\n",
    "os.environ[\"NEP50_DEPRECATION_WARNING\"] = \"0\"\n",
    "os.environ[\"NEP50_DISABLE_WARNING\"] = \"1\"\n",
    "os.environ[\"NPY_PROMOTION_STATE\"] = \"weak\"\n",
    "if not hasattr(np, \"_no_pep50_warning\"):\n",
    "\n",
    "    import contextlib\n",
    "    from typing import Generator\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _np_no_nep50_warning() -> Generator[None, None, None]:\n",
    "        \"\"\"Dummy function to avoid the warning.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        None\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "        yield\n",
    "\n",
    "    setattr(np, \"_no_pep50_warning\", _np_no_nep50_warning)  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94cd4eb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f083cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_logging() -> None:\n",
    "    \"\"\"Start logging.\"\"\"\n",
    "    runtime_logging.start(\n",
    "        logger_type=\"sqlite\",\n",
    "        config={\"dbname\": \"flow.db\"},\n",
    "    )\n",
    "\n",
    "\n",
    "start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850198a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Load model API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60695da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# This section assumes that a file named \"swarm_api_keys\"\n",
    "# exists in the same directory as this file.\n",
    "# This file contains the API keys for the models used in this flow.\n",
    "# It should be .gitignored and not shared publicly.\n",
    "# If this file is not present, you can either create it manually\n",
    "# or change the way API keys are loaded in the flow.\n",
    "\n",
    "\n",
    "def load_api_key_module(flow_name: str) -> ModuleType:\n",
    "    \"\"\"Load the api key module.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flow_name : str\n",
    "        The flow name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ModuleType\n",
    "        The api keys loading module.\n",
    "    \"\"\"\n",
    "    module_name = f\"{flow_name}_api_keys\"\n",
    "    if module_name in sys.modules:\n",
    "        return importlib.reload(sys.modules[module_name])\n",
    "    return importlib.import_module(module_name)\n",
    "\n",
    "\n",
    "__MODELS_MODULE__ = load_api_key_module(\"swarm\")\n",
    "\n",
    "\n",
    "def get_swarm_model_api_key(model_name: str) -> str:\n",
    "    \"\"\"Get the model api key.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        The model name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The model api key.\n",
    "    \"\"\"\n",
    "    return __MODELS_MODULE__.get_swarm_model_api_key(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d56cbb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c655eb5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Databases\n",
    "\n",
    "USER_DATABASE = {\n",
    "    \"mark\": {\n",
    "        \"full_name\": \"Mark Sze\",\n",
    "    },\n",
    "    \"kevin\": {\n",
    "        \"full_name\": \"Yiran Wu\",\n",
    "    },\n",
    "}\n",
    "\n",
    "ORDER_DATABASE = {\n",
    "    \"TR13845\": {\n",
    "        \"user\": \"mark\",\n",
    "        \"order_number\": \"TR13845\",\n",
    "        \"status\": \"shipped\",  # order status: order_received, shipped, delivered, return_started, returned\n",
    "        \"return_status\": \"N/A\",  # return status: N/A, return_started, return_shipped, return_delivered, refund_issued\n",
    "        \"product\": \"matress\",\n",
    "        \"link\": \"https://www.example.com/TR13845\",\n",
    "        \"shipping_address\": \"123 Main St, State College, PA 12345\",\n",
    "    },\n",
    "    \"TR14234\": {\n",
    "        \"user\": \"kevin\",\n",
    "        \"order_number\": \"TR14234\",\n",
    "        \"status\": \"delivered\",\n",
    "        \"return_status\": \"N/A\",\n",
    "        \"product\": \"pillow\",\n",
    "        \"link\": \"https://www.example.com/TR14234\",\n",
    "        \"shipping_address\": \"123 Main St, State College, PA 12345\",\n",
    "    },\n",
    "    \"TR29384\": {\n",
    "        \"user\": \"mark\",\n",
    "        \"order_number\": \"TR29384\",\n",
    "        \"status\": \"delivered\",\n",
    "        \"return_status\": \"N/A\",\n",
    "        \"product\": \"bed frame\",\n",
    "        \"link\": \"https://www.example.com/TR29384\",\n",
    "        \"shipping_address\": \"123 Main St, State College, PA 12345\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def record_order_id(\n",
    "    order_id: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Record the order ID in the workflow context\"\"\"\n",
    "    target = AgentNameTarget(\"order_triage_agent\")\n",
    "    if order_id not in ORDER_DATABASE:\n",
    "        return ReplyResult(\n",
    "            target=target,\n",
    "            context_variables=context_variables,\n",
    "            message=f\"Order ID {order_id} not found. Please ask for the correct order ID.\",\n",
    "        )\n",
    "\n",
    "    context_variables[\"order_id\"] = order_id\n",
    "    context_variables[\"has_order_id\"] = True\n",
    "    return ReplyResult(\n",
    "        target=target,\n",
    "        context_variables=context_variables,\n",
    "        message=f\"Order ID Recorded: {order_id}\",\n",
    "    )\n",
    "\n",
    "\n",
    "def check_order_id(\n",
    "    order_id: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Check if the order ID is valid\"\"\"\n",
    "    target = AgentNameTarget(\"order_triage_agent\")\n",
    "    # Restricts order to checking to the logged in user\n",
    "    if (\n",
    "        context_variables[\"logged_in_username\"]\n",
    "        and order_id in ORDER_DATABASE\n",
    "        and ORDER_DATABASE[order_id][\"user\"]\n",
    "        == context_variables[\"logged_in_username\"]\n",
    "    ):\n",
    "        return ReplyResult(\n",
    "            target=target,\n",
    "            context_variables=context_variables,\n",
    "            message=f\"Order ID {order_id} is valid.\",\n",
    "        )\n",
    "    return ReplyResult(\n",
    "        target=target,\n",
    "        context_variables=context_variables,\n",
    "        message=f\"Order ID {order_id} is invalid. Please ask for the correct order ID.\",\n",
    "    )\n",
    "\n",
    "\n",
    "def login_customer_by_username(\n",
    "    username: str, context_variables: ContextVariables\n",
    ") -> ReplyResult:\n",
    "    \"\"\"Get and log the customer in by their username\"\"\"\n",
    "    target = AgentNameTarget(\"authentication_agent\")\n",
    "    if username in USER_DATABASE:\n",
    "        context_variables[\"customer_name\"] = USER_DATABASE[username][\n",
    "            \"full_name\"\n",
    "        ]\n",
    "        context_variables[\"logged_in_username\"] = username\n",
    "        context_variables[\"logged_in\"] = True\n",
    "        context_variables[\"requires_login\"] = False\n",
    "        return ReplyResult(\n",
    "            context_variables=context_variables,\n",
    "            message=f\"Welcome back our customer, {context_variables['customer_name']}! Please continue helping them.\",\n",
    "        )\n",
    "    return ReplyResult(\n",
    "        target=target,\n",
    "        context_variables=context_variables,\n",
    "        message=f\"User {username} not found. Please ask for the correct username.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07204710",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dab6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_4_turbo_llm_config: dict[str, Any] = {\n",
    "    \"model\": \"gpt-4-turbo\",\n",
    "    \"api_type\": \"openai\",\n",
    "    \"api_key\": get_swarm_model_api_key(\"gpt_4_turbo\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d2217",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportUnnecessaryIsInstance=false\n",
    "\n",
    "authentication_agent_executor = LocalCommandLineCodeExecutor(\n",
    "    work_dir=\"coding\",\n",
    "    timeout=60,\n",
    ")\n",
    "\n",
    "authentication_agent = ConversableAgent(\n",
    "    name=\"authentication_agent\",\n",
    "    description=\"Authentication Agent\",\n",
    "    system_message=\"You are an authentication agent that verifies the identity of the customer.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config={\"executor\": authentication_agent_executor},\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    functions=[\n",
    "        login_customer_by_username,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "customer = UserProxyAgent(\n",
    "    name=\"customer\",\n",
    "    description=\"The customer user proxy agent.\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    llm_config=False,  # pyright: ignore\n",
    ")\n",
    "\n",
    "order_mgmt_agent = ConversableAgent(\n",
    "    name=\"order_mgmt_agent\",\n",
    "    description=\"Order Management Agent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    functions=[\n",
    "        check_order_id,\n",
    "        record_order_id,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[\n",
    "        UpdateSystemMessage(\n",
    "            \"You are an order management agent that manages inquiries related to e-commerce orders.\\n\\nThe order must be logged in to access their order.\\n\\nUse your available tools to get the status of the details from the customer. Ask the customer questions as needed.\\n\\nUse the check_order_id tool before the record_order_id tool, never together.\\n\\nThe current status of this workflow is:\\nCustomer name: {customer_name}\\nLogged in: {logged_in}\\nEnquiring for Order ID: {order_id}\"\n",
    "        ),\n",
    "    ],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "order_retrieval_agent = AssistantAgent(\n",
    "    name=\"order_retrieval_agent\",\n",
    "    description=\"An order retrieval agent that gets details about an order.\",\n",
    "    system_message=\"You are an order retrieval agent that gets details about an order.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "order_summariser_agent = AssistantAgent(\n",
    "    name=\"order_summariser_agent\",\n",
    "    description=\"An order summariser agent that provides a summary of the order details.\",\n",
    "    system_message=\"You are an order summariser agent that provides a summary of the order details.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "order_triage_agent = ConversableAgent(\n",
    "    name=\"order_triage_agent\",\n",
    "    description=\"Order Triage Agent\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=None,\n",
    "    default_auto_reply=\"\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=None,  # pyright: ignore\n",
    "    functions=[\n",
    "        check_order_id,\n",
    "        record_order_id,\n",
    "    ],\n",
    "    update_agent_state_before_reply=[\n",
    "        UpdateSystemMessage(\n",
    "            \"You are an order triage agent, working with a customer and a group of agents to provide support for your e-commerce platform.\\n\\nAn agent needs to be logged in to be able to access their order. The authentication_agent will work with the customer to verify their identity, transfer to them to start with.\\nThe order_mgmt_agent will manage all order related tasks, such as tracking orders, managing orders, etc. Be sure to check the order as one step. Then if it's valid you can record it in the context.\\n\\nAsk the customer for further information when necessary.\\n\\nThe current status of this workflow is:\\nCustomer name: {customer_name}\\nLogged in: {logged_in}\\nEnquiring for Order ID: {order_id}\"\n",
    "        ),\n",
    "    ],\n",
    "    llm_config=autogen.LLMConfig(\n",
    "        config_list=[\n",
    "            gpt_4_turbo_llm_config,\n",
    "        ],\n",
    "        cache_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "authentication_agent.handoffs.add_context_condition(\n",
    "    condition=OnContextCondition(\n",
    "        target=AgentTarget(order_triage_agent),\n",
    "        condition=StringContextCondition(variable_name=\"logged_in\"),\n",
    "    )\n",
    ")\n",
    "authentication_agent.handoffs.set_after_work(target=RevertToUserTarget())\n",
    "\n",
    "order_mgmt_agent.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=AgentTarget(authentication_agent),\n",
    "        condition=StringLLMCondition(\n",
    "            prompt=\"The customer is not logged in, authenticate the customer.\"\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"!(${logged_in})\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "order_mgmt_agent.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=AgentTarget(order_triage_agent),\n",
    "        condition=StringLLMCondition(\n",
    "            prompt=\"The customer has no more enquiries about this order.\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def nested_chat_message_wc_getorderstatus(\n",
    "    recipient: ConversableAgent,\n",
    "    messages: list[dict[str, Any]],\n",
    "    sender: ConversableAgent,\n",
    "    config: dict[str, Any],\n",
    ") -> Union[dict[str, Any], str]:\n",
    "    \"\"\"Extract the order summary based on the OrderID in the context variables\"\"\"\n",
    "    order_id = sender.context_variables.get(\"order_id\")\n",
    "    if order_id and order_id in ORDER_DATABASE:\n",
    "        order = ORDER_DATABASE[order_id]\n",
    "        address = order[\"shipping_address\"]\n",
    "        order_no = order[\"order_number\"]\n",
    "        product = order[\"product\"]\n",
    "        status = order[\"status\"]\n",
    "        return f\"Order {order_no} for {product} is currently {status}. The shipping address is {address}.\"\n",
    "    return f\"Order {order_id} not found.\"\n",
    "\n",
    "\n",
    "order_mgmt_agent_handoff_nested_chat_queue: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"summary_method\": \"last_msg\",\n",
    "        \"clear_history\": True,\n",
    "        \"chat_id\": 5,\n",
    "        \"recipient\": order_summariser_agent,\n",
    "        \"message\": \"Summarise the order details provided in a tabulated, text-based, order sheet format.\",\n",
    "    },\n",
    "    {\n",
    "        \"summary_method\": \"last_msg\",\n",
    "        \"clear_history\": True,\n",
    "        \"chat_id\": 6,\n",
    "        \"recipient\": order_retrieval_agent,\n",
    "        \"message\": nested_chat_message_wc_getorderstatus,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "order_mgmt_agent.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=NestedChatTarget(\n",
    "            nested_chat_config={\n",
    "                \"chat_queue\": order_mgmt_agent_handoff_nested_chat_queue\n",
    "            }\n",
    "        ),\n",
    "        condition=StringLLMCondition(\n",
    "            prompt=\"Retrieve the status of the order.\"\n",
    "        ),\n",
    "        available=StringAvailableCondition(\"has_order_id\"),\n",
    "    )\n",
    ")\n",
    "order_mgmt_agent.handoffs.set_after_work(target=RevertToUserTarget())\n",
    "\n",
    "order_triage_agent.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=AgentTarget(authentication_agent),\n",
    "        condition=StringLLMCondition(\n",
    "            prompt=\"The customer is not logged in, authenticate the customer.\"\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "order_triage_agent.handoffs.add_llm_condition(\n",
    "    condition=OnCondition(\n",
    "        target=AgentTarget(order_mgmt_agent),\n",
    "        condition=StringLLMCondition(\n",
    "            prompt=\"The customer is logged in, continue with the order triage.\"\n",
    "        ),\n",
    "        available=ExpressionAvailableCondition(\n",
    "            expression=ContextExpression(\"!(${logged_in})\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "order_triage_agent.handoffs.set_after_work(target=RevertToUserTarget())\n",
    "\n",
    "manager_pattern = DefaultPattern(\n",
    "    initial_agent=order_triage_agent,\n",
    "    agents=[order_triage_agent, order_mgmt_agent, authentication_agent],\n",
    "    user_agent=customer,\n",
    "    group_manager_args={\n",
    "        \"llm_config\": autogen.LLMConfig(\n",
    "            config_list=[\n",
    "                gpt_4_turbo_llm_config,\n",
    "            ],\n",
    "            cache_seed=None,\n",
    "        ),\n",
    "    },\n",
    "    context_variables=ContextVariables(\n",
    "        data={\n",
    "            \"customer_name\": None,\n",
    "            \"logged_in_username\": None,\n",
    "            \"logged_in\": False,\n",
    "            \"requires_login\": True,\n",
    "            \"has_order_id\": False,\n",
    "            \"order_id\": None,\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def get_sqlite_out(dbname: str, table: str, csv_file: str) -> None:\n",
    "    \"\"\"Convert a sqlite table to csv and json files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dbname : str\n",
    "        The sqlite database name.\n",
    "    table : str\n",
    "        The table name.\n",
    "    csv_file : str\n",
    "        The csv file name.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(dbname)\n",
    "    query = f\"SELECT * FROM {table}\"  # nosec\n",
    "    try:\n",
    "        cursor = conn.execute(query)\n",
    "    except sqlite3.OperationalError:\n",
    "        conn.close()\n",
    "        return\n",
    "    rows = cursor.fetchall()\n",
    "    column_names = [description[0] for description in cursor.description]\n",
    "    data = [dict(zip(column_names, row)) for row in rows]\n",
    "    conn.close()\n",
    "    with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        csv_writer = csv.DictWriter(file, fieldnames=column_names)\n",
    "        csv_writer.writeheader()\n",
    "        csv_writer.writerows(data)\n",
    "    json_file = csv_file.replace(\".csv\", \".json\")\n",
    "    with open(json_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def stop_logging() -> None:\n",
    "    \"\"\"Stop logging.\"\"\"\n",
    "    runtime_logging.stop()\n",
    "    if not os.path.exists(\"logs\"):\n",
    "        os.makedirs(\"logs\")\n",
    "    for table in [\n",
    "        \"chat_completions\",\n",
    "        \"agents\",\n",
    "        \"oai_wrappers\",\n",
    "        \"oai_clients\",\n",
    "        \"version\",\n",
    "        \"events\",\n",
    "        \"function_calls\",\n",
    "    ]:\n",
    "        dest = os.path.join(\"logs\", f\"{table}.csv\")\n",
    "        get_sqlite_out(\"flow.db\", table, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aea698",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Start chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63c722",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main() -> Union[ChatResult, list[ChatResult], dict[int, ChatResult]]:\n",
    "    \"\"\"Start chatting.\n",
    "    Returns\n",
    "    -------\n",
    "    Union[ChatResult, list[ChatResult], dict[int, ChatResult]]\n",
    "        The result of the chat session, which can be a single ChatResult,\n",
    "        a list of ChatResults, or a dictionary mapping integers to ChatResults.\n",
    "    \"\"\"\n",
    "    with Cache.disk(cache_seed=42) as cache:  # pyright: ignore\n",
    "        results, _, __ = initiate_group_chat(\n",
    "            pattern=manager_pattern,\n",
    "            messages=\"Help me with my order\",\n",
    "            max_rounds=40,\n",
    "        )\n",
    "\n",
    "        stop_logging()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "comment_magics": false,
   "hide_notebook_metadata": true,
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
